[
  {
    "objectID": "logbook/posts/2024_07_30/index.html",
    "href": "logbook/posts/2024_07_30/index.html",
    "title": "Day 3",
    "section": "",
    "text": "Note\n\n\n\nReproduced Figure 1 and Table 2. Total time used: 8h 59m (22.5%)."
  },
  {
    "objectID": "logbook/posts/2024_07_30/index.html#timings-below-working-on-table-2-and-figure-1",
    "href": "logbook/posts/2024_07_30/index.html#timings-below-working-on-table-2-and-figure-1",
    "title": "Day 3",
    "section": "Timings below: Working on Table 2 and Figure 1",
    "text": "Timings below: Working on Table 2 and Figure 1\nTimings:\n\n09.10-09.11\n09.20-09.22\n09.30-09.40\n09.52-10.44\n10.51-10.56\n11.02-11.56\n12.59-13.27\n\n\nGitHub repository dates\nI realised I had forgotten to check the GitHub repository dates v.s. paper dates. The article was published in June 2021. There are three commits after this point:\n\n19 July 2021 - “Adding SWAN models to repository” - relevant changes:\n\ndebug=F and some error handling in processPersons() from DES_Model.R\nChanging from v1other$aortaDiameterThresholds &lt;- c(3.0, 4.5, 5.5) to v1other$aortaDiameterThresholds &lt;- list(c(3.0, 4.5, 5.5)) in input/NAAASP_Men_2020-05-11/DES_Data_Input_NAAASP_Men_30years_time_horizon_2020-05-11.R\nRemoving an associated .xlsx file for 202-05-11\n\n19 July 2021 - “Updating README.md”\n\nMore detail in README (see below)\n\n12 February 2024 - “Fixed checks with vectorised elements, which was causing errors in R v4.3”\n\nAdd .gitignore\nModification in Auxillary_Functions.R\nFormatting in DES_Model.R\n\n\nOriginal:\n\nThe following directories are included:\n/models – R scripts that run the DES models for AAA screening\n/models/Example – An example script to run the DES is contained here\n/functions – Contains the DES model code\n/input – Contains the input parameters and .csv files needed to run the DES models\n/input/NAAASP_Men_2020-05-11 – Updated parameters for AAA screening in men, updated as of 11/05/2020\n/output – Directory where Rdata output files are saved\n\nNew:\n\nThe following directories are included:\n\n/models – R scripts that run the DES models for AAA screening\n/models/Example – An example script to run the DES is contained here\n/models/SWAN – Screening Women for Abdominal Aortic Aneurysm (SWAN) model scripts. See our Lancet publication and HTA report for further details\n/models/NAAASP_COVID_modelling – Scripts for modelling the impact of changes to Abdominal Aortic Aneurysm screening and treatment services in England during the COVID-19 pandemic. See our PLOS ONE publication for further details\n/functions – Contains the DES model code\n/input – Contains the input parameters and .csv files needed to run the DES models\n/input/SWAN – Screening Women for Abdominal Aortic Aneurysm (SWAN) input parameters. See our Lancet publication and HTA report for further details\n/input/NAAASP_COVID_modelling – Input parameters for modelling the impact of changes to Abdominal Aortic Aneurysm screening and treatment services in England during the COVID-19 pandemic. See our PLOS ONE publication for further details\n/input/NAAASP_Men_2020-05-11 – Updated parameters for AAA screening in men, updated as of 11/05/2020\n/output – Directory where Rdata output files are saved\n\n\n\n\n\n\n\n\nReflection\n\n\n\nGiven how far I have progressed with this, I won’t go back to using the version as of publication, but we should bare this in mind later.\n\n\n\n\nIncrementing number of people for 65yo scen1\nRan full script of run_aaamodel-65yo_scen1.R with 100,000 people and parallel. However, this evidently is still too few people, looking at the results.\n\nimport pandas as pd\n\npd.read_csv('tab2_100k.csv')\n\n\n\n\n\n\n\n\ndelayscr\nexcess_death\nexcess_op\n\n\n\n\n0\n0.00\n0\n0\n\n\n1\n0.25\n-6\n-3\n\n\n2\n0.50\n-5\n3\n\n\n3\n1.00\n-6\n-1\n\n\n4\n2.00\n-1\n-3\n\n\n5\n3.00\n2\n3\n\n\n6\n4.00\n25\n7\n\n\n7\n5.00\n41\n7\n\n\n\n\n\n\n\nI pulled changes to files and renv onto remote computer, and then ran that with 1,000,000 people. To open and change file:\nnano 'models/NAAASP_COVID_modelling/run_aaamodel_65yo_scen1.R'\nTo run:\nRscript -e \"source('models/NAAASP_COVID_modelling/run_aaamodel_65yo_scen1.R')\"\nPer run this took:\n\n3 minutes 46 seconds on remote computer - so estimated 30 minutes in total.\n13 minutes 44 seconds on local computer - so would be an estimated 1 hour 50 minutes in total\n\nLooking at the convergence plots (supplementary figure 1 and 2), 1 million people is nearing closer to convergence - but 2 million even more-so.\n\nimport pandas as pd\n\npd.read_csv('tab2_1m.csv')\n\n\n\n\n\n\n\n\ndelayscr\naaadead\nemeropen\nexcess_death\nexcess_op\n\n\n\n\n0\n0.00\n9226\n2830\n0\n0\n\n\n1\n0.25\n9200\n2824\n-26\n-6\n\n\n2\n0.50\n9194\n2843\n-32\n13\n\n\n3\n1.00\n9199\n2830\n-27\n0\n\n\n4\n2.00\n9210\n2836\n-16\n6\n\n\n5\n3.00\n9298\n2878\n72\n48\n\n\n6\n4.00\n9423\n2933\n197\n103\n\n\n7\n5.00\n9612\n2993\n386\n163\n\n\n\n\n\n\n\n\n\nScaling the numbers\nLooking at the result, I’m a little uncertain over the numbers we are getting. Looking at Table 2’s caption, I’m thinking that perhaps I may need to scale these (as using the raw numbers from the simulation, we’d expect these to be less than the table). The caption mentions that the:\n\nNational male 65 year old cohort for England: n = 279,798\nExpected AAA deaths over 30y in status quo = 2564\nExpected emergency operations over 30y in status quo = 1041\n\nI tried scaling the results so that it reflects deaths expected if population were 279,798 (rather than 1 million). I scaled the results from aaadead and emerevar (e.g. round(279798*(aaadead/1000000))). The number of deaths looks similar to the expected from Table 2 (2564), but the number of emergency operations is very different.\n\nimport pandas as pd\n\npd.read_csv('scaled_1m.csv')\n\n\n\n\n\n\n\n\ndelayscr\naaadead\nscaled_dead\nscaled_emer\n\n\n\n\n0\n0.00\n9226\n2581\n261\n\n\n1\n0.25\n9200\n2574\n261\n\n\n2\n0.50\n9194\n2572\n261\n\n\n3\n1.00\n9199\n2574\n261\n\n\n4\n2.00\n9210\n2577\n261\n\n\n5\n3.00\n9298\n2602\n261\n\n\n6\n4.00\n9423\n2637\n261\n\n\n7\n5.00\n9612\n2689\n261\n\n\n\n\n\n\n\n\n\nScenario 0\nI was wondering whether this should be compared against the result from the status quo script rather than from when delay is 0 (or whether that should just be the same thing anyway!).\nI repeated this for the results from scenario 0 (status quo):\nscale_dead_s0 &lt;- y65_s0 %&gt;%\n  select(aaadead) %&gt;%\n  mutate(scaled_dead = round(279798*(aaadead/1000000)))\nwrite.csv(scale_dead_s0, \"../../logbook/posts/2024_07_30/dead_s0.csv\", row.names=FALSE)\nIt came out exactly the same, so seems, no issue with using the 0 result from the run of scen1.\n\nimport pandas as pd\n\npd.read_csv('dead_s0.csv')\n\n\n\n\n\n\n\n\naaadead\nscaled_dead\n\n\n\n\n0\n9226\n2581\n\n\n\n\n\n\n\n\n\nConfirming which column gives number of operations\nGiven that number of emergency operations looked very different, I was suspicious if I was using the correct column for this. It seems clear that deaths and ruptures are aaadead and rupt respectively, but I was less certain for surgeries (elecopen vs elecevar) (emeropen vs emerevar).\nI tried applying scaling to every column from row 1, to see which came out most similar.\nas.data.frame(t(head(y65_s1, 1))) %&gt;%\n  rename(result = 1) %&gt;%\n  mutate(scaled = round(279798*(result/n_person)))\nBased on the names, there are a few candidates for emergency operations: emerevar, emeropen, reintemerevar and reintemeropen. I’m not certain what the difference is between these, but starting with their scaled values:\n\nemerevar - 242\nemeropen - 790\nreintemerevar - 935\nreintemeropen - 183\n\nThe expected number is 1041, so reintemerevar does appear closest.\n\nimport pandas as pd\n\npd.read_csv('scale_all_first_row.csv', index_col=0)\n\n\n\n\n\n\n\n\nresult\nscaled\n\n\n\n\nn\n1000000.00\n279798\n\n\ndelayscr\n0.25\n0\n\n\ninv\n997073.00\n278979\n\n\nscr\n748352.00\n209387\n\n\nreinv\n135543.00\n37925\n\n\nnonatt\n248721.00\n69592\n\n\nmonitor\n265786.00\n74366\n\n\ndropout\n9445.00\n2643\n\n\noppdet\n28438.00\n7957\n\n\nconsult\n25555.00\n7150\n\n\nelecevar\n10721.00\n3000\n\n\nelecopen\n4739.00\n1326\n\n\nrupt\n10093.00\n2824\n\n\nemerevar\n865.00\n242\n\n\nemeropen\n2824.00\n790\n\n\nreintelecevar\n3340.00\n935\n\n\nreintemerevar\n3340.00\n935\n\n\nreintemeropen\n655.00\n183\n\n\naaadead\n9200.00\n2574\n\n\nnonaaadead\n909861.00\n254577\n\n\n\n\n\n\n\nI also then looked into the repository, for any written explanation for each variable, or the code behind it, to help confirm which is appropriate. Looking across the repository, these columns are created within each of the scenario scripts. From run_aaamodel_65yo_scen1.R:\nelecevar&lt;-Eventsandcosts(scen1.invite)[14,2]\nelecopen&lt;-Eventsandcosts(scen1.invite)[15,2]\n\nemerevar&lt;-Eventsandcosts(scen1.invite)[17,2]\nemeropen&lt;-Eventsandcosts(scen1.invite)[18,2]\n\nreintelecevar&lt;-Eventsandcosts(scen1.invite)[21,2]\nreintemerevar&lt;-Eventsandcosts(scen1.invite)[21,2]\nLooking directly at the output of Eventsandcosts(scen1.invite) I can see that these match up with:\n\n14 - electiveSurgeryEvar\n15 - electiveSurgeryOpen\n17 - emergencySurgeryEvar\n18 - emergencySurgeryOpen\n21- reinterventionAfterElectiveEvar\n\nI’m not certain why reintemerevar uses 21 and not 22, as 22 is reinterventionAfterEmergencyEvar, but this appears to be the same in each of the scenario scripts.\nThese are assigned from costs, and v2$costs is in the data dictionary, DES_Input_Definitions.xlsx:\n\nelectiveSurgeryEvar: Elective EVAR repair\nelectiveSurgeryOpen: Elective Open repair\nemergencySurgeryEvar: Emergency EVAR repair\nemergencySurgeryOpen: Emergency Open repair\nreinterventionAfterElectiveEvar: Re-intervention after elective EVAR\n\nHaving looked at this, I am presuming that the number of emergency operations would be given by combining emergencySurgeryEvar (17) (emerevar) and emergencySurgeryOpen (18) (emeropen).\nOnce I did that, the numbers looked much closer to the expected 1041 from the paper, with 1034 from 1 million people, and 1028 from 2 million people.\n\n\nExcess deaths\nI’m seeing some negatives (but the paper does not, and has several 0). I’m wondering if, as the result is “excess” deaths, perhaps I should only be counting when it was over 0 (and setting negative numbers to 0), so I altered it accordingly.\nI also trimmed down the rows displayed for Table 2, to make the article.\n\n\nTwo million people\nI ran run_aaamodel_65yo_scen1.R again but with 2 million people, as that looks like a more appropriate figure from the convergence plots, but I wasn’t certain if:\n\n\nthe remote computer would manage it (process killed when ran with 10 million)\n\n\nhow long it would take\n\n\nhow much of a difference it would make\n\n\nRE: (a) - it did manage it. While running, I did note we are now getting very large objects from each run (e.g. processPersons is about to return an object of size 4.5 Gb)\nRE: (b) - the time for one run with 2 million people was 11 minutes 20 seconds. For all eight runs, it took a total of “1.01512100968096” (which is weird - normally it gives me a result in minutes). If we assume this is hours, it’s just over an hour. My estimate based on the time for one run would be 1 hour 30 minutes. Have changed the timing statement to use difftime instead with units specified to avoid this issue in future.\nRE: (c) - the results are pretty similar. I renamed the output files to we had results with 1 million and 2 million, then applied same function to create table 2, and they were pretty similar.\n\nimport pandas as pd\n\ndisplay(pd.read_csv('tab2_correct_1m.csv'))\ndisplay(pd.read_csv('tab2_correct_2m.csv'))\n\n\n\n\n\n\n\n\nmonths\nexcess_dead\nexcess_emer\n\n\n\n\n0\n6m\n0\n3\n\n\n1\n12m\n0\n0\n\n\n2\n24m\n0\n1\n\n\n3\n36m\n21\n14\n\n\n4\n48m\n56\n35\n\n\n5\n60m\n108\n56\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmonths\nexcess_dead\nexcess_emer\n\n\n\n\n0\n6m\n0\n0\n\n\n1\n12m\n0\n0\n\n\n2\n24m\n0\n0\n\n\n3\n36m\n20\n11\n\n\n4\n48m\n50\n31\n\n\n5\n60m\n105\n60\n\n\n\n\n\n\n\nGiven their similarity, I will continue with running the simulation with 1 million people for the time being, since running with 2 million was much longer and very computationally expensive."
  },
  {
    "objectID": "logbook/posts/2024_07_30/index.html#running-65-year-old-scenario-2",
    "href": "logbook/posts/2024_07_30/index.html#running-65-year-old-scenario-2",
    "title": "Day 3",
    "section": "13.29-13.39: Running 65 year old scenario 2",
    "text": "13.29-13.39: Running 65 year old scenario 2\nScenario 2 has a delay to invitation of 6 months, and attendance of 45 to 75%. This is required for Table 2, which also displays results from attendance of 65%, 55% and 45% (compared against 75%).\nI set this up to run on the remote computer, with the changes as before, of:\n\nUsing parallel\n1 million\nSaving the results to csv\nCommenting out list(v1other$aortaDiameterThresholds)\nTimings for one run and all runs\n\nTimings:\n\nOne run: 3.952 minutes = 237 seconds = 3 minutes 57 seconds\nFull run: 19.123 minutes = 1147 seconds = 19 minutes 7 seconds"
  },
  {
    "objectID": "logbook/posts/2024_07_30/index.html#running-surv-scenario-1",
    "href": "logbook/posts/2024_07_30/index.html#running-surv-scenario-1",
    "title": "Day 3",
    "section": "14.00-14.06: Running surv scenario 1",
    "text": "14.00-14.06: Running surv scenario 1\nMidway through creating figure 1, I set remote computer to run another scenario.\nAmended script as did for 65yo scen2, with an additional fix too - correct path to model script to DES_Model.R - and then ran on remote machine.\nTimings:\n\nOne run: 13.368 minutes = 802 seconds = 13 minutes 22 seconds\nFull run: 70.183 minutes = 4211 seconds = 1 hour 10 minutes 11 seconds\n\nThis runtime reaffirmed for me the use of 1,000,000 people (rather than 2,000,000)."
  },
  {
    "objectID": "logbook/posts/2024_07_30/index.html#creating-figure-1",
    "href": "logbook/posts/2024_07_30/index.html#creating-figure-1",
    "title": "Day 3",
    "section": "13.40-13.44, 13.51-13.59, 14.07-14.29: Creating Figure 1",
    "text": "13.40-13.44, 13.51-13.59, 14.07-14.29: Creating Figure 1\nWhilst that ran - and then, setting others to run during this too (hence time jumps) - I set about creating Figure 1 from the results of scenario 1 with 1 million people.\nAdd ggplot2 (to make plots) and tidyr (to melt dataframe) to renv.\nWrote code to create figure, and was satisified this was reproduced at 14.29.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 243\n\n# Times from today\ntimes = [\n    ('09.10', '09.11'),\n    ('09.20', '09.22'),\n    ('09.30', '09.40'),\n    ('09.52', '10.44'),\n    ('10.51', '10.56'),\n    ('11.02', '11.56'),\n    ('12.59', '13.27'),\n    ('13.29', '13.39'),\n    ('13.40', '13.44'),\n    ('13.51', '13.59'),\n    ('14.00', '14.06'),\n    ('14.07', '14.29')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 202m, or 3h 22m\nTotal used to date: 445m, or 7h 25m\nTime remaining: 1955m, or 32h 35m\nUsed 18.5% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_30/index.html#checking-scenario-1-simulation-table-2-results",
    "href": "logbook/posts/2024_07_30/index.html#checking-scenario-1-simulation-table-2-results",
    "title": "Day 3",
    "section": "14.42-14.49: Checking scenario 1 simulation table 2 results",
    "text": "14.42-14.49: Checking scenario 1 simulation table 2 results\nNow that we have the function to process scenario 1 correctly, I went back to re-run the results from fewer numbers of people, just to reaffirm whether the chosen number is appropriate (or whether we could use fewer).\nI downloaded the results from my GitHub commit history, renaming the files to indicating the number of people.\nWith each of the variants I’d tried, it is apparent that none below 1 million were appropriate. It is possible that there could have been an appropriate inbetween value that I hadn’t tried (e.g. 500,000), but for now, I will stick with 1 million.\n\nimport pandas as pd\n\ndisplay(pd.read_csv('65y_s1_tab2_1k.csv'))\ndisplay(pd.read_csv('65y_s1_tab2_10k.csv'))\ndisplay(pd.read_csv('65y_s1_tab2_100k.csv'))\ndisplay(pd.read_csv('65y_s1_tab2_1m.csv'))\ndisplay(pd.read_csv('65y_s1_tab2_2m.csv'))\n\n\n\n\n\n\n\n\nmonths\nexcess_dead_emer\n\n\n\n\n0\n6m\n0 (NA)\n\n\n1\n12m\n0 (NA)\n\n\n2\n24m\n0 (NA)\n\n\n3\n36m\n0 (NA)\n\n\n4\n48m\n279 (NA)\n\n\n5\n60m\n279 (NA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmonths\nexcess_dead_emer\n\n\n\n\n0\n6m\n56 (0)\n\n\n1\n12m\n0 (0)\n\n\n2\n24m\n56 (0)\n\n\n3\n36m\n56 (0)\n\n\n4\n48m\n140 (0)\n\n\n5\n60m\n196 (0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmonths\nexcess_dead_emer\n\n\n\n\n0\n6m\n0 (6)\n\n\n1\n12m\n0 (0)\n\n\n2\n24m\n0 (0)\n\n\n3\n36m\n5 (6)\n\n\n4\n48m\n70 (25)\n\n\n5\n60m\n114 (25)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmonths\nexcess_dead_emer\n\n\n\n\n0\n6m\n0 (3)\n\n\n1\n12m\n0 (0)\n\n\n2\n24m\n0 (1)\n\n\n3\n36m\n21 (14)\n\n\n4\n48m\n56 (35)\n\n\n5\n60m\n108 (56)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmonths\nexcess_dead_emer\n\n\n\n\n0\n6m\n0 (0)\n\n\n1\n12m\n0 (0)\n\n\n2\n24m\n0 (0)\n\n\n3\n36m\n20 (11)\n\n\n4\n48m\n50 (31)\n\n\n5\n60m\n105 (60)"
  },
  {
    "objectID": "logbook/posts/2024_07_30/index.html#table-2",
    "href": "logbook/posts/2024_07_30/index.html#table-2",
    "title": "Day 3",
    "section": "15.00-15.59: Table 2",
    "text": "15.00-15.59: Table 2\nModified function so it could be used to process both scenarios, then combined into a single table.\nI was satisfied this was reproduced (within expected variation from running with less people) at 15.59.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 243\n\n# Times from today\ntimes = [\n    ('09.10', '09.11'),\n    ('09.20', '09.22'),\n    ('09.30', '09.40'),\n    ('09.52', '10.44'),\n    ('10.51', '10.56'),\n    ('11.02', '11.56'),\n    ('12.59', '13.27'),\n    ('13.29', '13.39'),\n    ('13.40', '13.44'),\n    ('13.51', '13.59'),\n    ('14.00', '14.06'),\n    ('14.07', '14.29'),\n    ('14.42', '14.49'),\n    ('15.00', '15.59')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 268m, or 4h 28m\nTotal used to date: 511m, or 8h 31m\nTime remaining: 1889m, or 31h 29m\nUsed 21.3% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_30/index.html#fix-later-scenarios",
    "href": "logbook/posts/2024_07_30/index.html#fix-later-scenarios",
    "title": "Day 3",
    "section": "16.12-16.27: Fix later scenarios",
    "text": "16.12-16.27: Fix later scenarios\nFixed surv scenarios 2 to 4e (although not yet running as potentially insufficient time to complete before end of work day). As above, fixes include:\n\nUsing parallel\n1 million\nSaving the results to csv\nCommenting out list(v1other$aortaDiameterThresholds)\nTimings for one run and all runs\nCorrecting filename when source DES_Model.R\n\n\n\n\n\n\n\nReflection\n\n\n\nI haven’t modified the provided structure of seperate scripts, but this structure does make it challenging when you want to change a parameter across the runs, as you have to carefully change each of the scripts. It would be easier if they were controlled by a single set of shared parameters."
  },
  {
    "objectID": "logbook/posts/2024_07_30/index.html#start-on-figure-2",
    "href": "logbook/posts/2024_07_30/index.html#start-on-figure-2",
    "title": "Day 3",
    "section": "16.42-16.55: Start on Figure 2",
    "text": "16.42-16.55: Start on Figure 2\nCreate function based on Figure 1, so can reuse same processing code to generate dataframe for the figure."
  },
  {
    "objectID": "logbook/posts/2024_07_30/index.html#timings",
    "href": "logbook/posts/2024_07_30/index.html#timings",
    "title": "Day 3",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 243\n\n# Times from today\ntimes = [\n    ('09.10', '09.11'),\n    ('09.20', '09.22'),\n    ('09.30', '09.40'),\n    ('09.52', '10.44'),\n    ('10.51', '10.56'),\n    ('11.02', '11.56'),\n    ('12.59', '13.27'),\n    ('13.29', '13.39'),\n    ('13.40', '13.44'),\n    ('13.51', '13.59'),\n    ('14.00', '14.06'),\n    ('14.07', '14.29'),\n    ('14.42', '14.49'),\n    ('15.00', '15.59'),\n    ('16.12', '16.27'),\n    ('16.42', '16.55')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 296m, or 4h 56m\nTotal used to date: 539m, or 8h 59m\nTime remaining: 1861m, or 31h 1m\nUsed 22.5% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html",
    "href": "logbook/posts/2024_07_29/index.html",
    "title": "Day 2",
    "section": "",
    "text": "Note\n\n\n\nRead article, decided on scope, then began running model. Total time used: 4h 3m (10.1%)."
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#high-entropy-secret",
    "href": "logbook/posts/2024_07_29/index.html#high-entropy-secret",
    "title": "Day 2",
    "section": "09.38-09.43: High entropy secret",
    "text": "09.38-09.43: High entropy secret\nUpload of code to repository triggered a notification from GitGuardian for upload of a high entropy secret. Opening the GitGuardian dashboard, I found the source of this issue was an API key uploaded to original_study/AAA_DES_model/input/NAAASP_Men_2020-05-11/DES_Data_Input_NAAASP_Men_30years_time_horizon_2020-05-11.R on line 376:\n# SOURCE: Love-Koh 2015 (https://reader.elsevier.com/reader/sd/pii/S1098301515018471?token=AB11057F469D57EBE990778CCDC883E9D35D3CFD83AD143352F3AD497E822198F957DBCE2EA86AE6DC16F2F6CE350409)\nThis is not a concern - the link doesn’t work with that token for others.\nThe DOI for this article is https://doi.org/10.1016/j.jval.2015.03.1784."
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#correct-file-paths",
    "href": "logbook/posts/2024_07_29/index.html#correct-file-paths",
    "title": "Day 2",
    "section": "09.53-09.55: Correct file paths",
    "text": "09.53-09.55: Correct file paths\nFor study_publication.qmd."
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#read-journal-article",
    "href": "logbook/posts/2024_07_29/index.html#read-journal-article",
    "title": "Day 2",
    "section": "10.05-10.15, 10.29-10.45: Read journal article",
    "text": "10.05-10.15, 10.29-10.45: Read journal article\nUses a previously developed and validated model described in:\n\nGlover MJ, Jones E, Masconi KL, Sweeting MJ, Thompson SG. Discrete Event Simulation for Decision Modeling in Health Care: Lessons from Abdominal Aortic Aneurysm Screening. Med Decis Making. 2018; 38(4):439–51. https://doi.org/10.1177/0272989X17753380 PMID: 31665967\nThompson SG, Bown MJ, Glover MJ, Jones E, Masconi KL, Michaels JA, et al. Screening women aged 65 years or over for abdominal aortic aneurysm: a modelling study and health economic evaluation. Health Technol Assess. 2018; 22(43):1–142. https://doi.org/10.3310/hta22430 PMID: 30132754\n\nSome notes on scope (beyond obvious tables/figures):\n\nIn-text result for Surveillance cohort: Scan suspension (re: breakdown of deaths by type) are not captured in tables/figures\nSupplementary figure 1 and 2 are more like methods than results? Are referenced in methods.\nIn-text results for Surveillance cohort: Drop-out are captured in Table 3 and Figure 4\nAlso captured are Surveillance cohort: Threshold for surgery\nSupplementary figure 3 and supplementary table 2 are definitely in scope"
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#define-scope-for-reproduction",
    "href": "logbook/posts/2024_07_29/index.html#define-scope-for-reproduction",
    "title": "Day 2",
    "section": "10.46-11.02: Define scope for reproduction",
    "text": "10.46-11.02: Define scope for reproduction\nI described my interpretation of scope within scope.qmd."
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#discussed-scope-with-tom",
    "href": "logbook/posts/2024_07_29/index.html#discussed-scope-with-tom",
    "title": "Day 2",
    "section": "11.09-11.13: Discussed scope with Tom",
    "text": "11.09-11.13: Discussed scope with Tom\nLooked over and happy with scope. He then did another look over the paper, but confirmed no further items."
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#archive-scope",
    "href": "logbook/posts/2024_07_29/index.html#archive-scope",
    "title": "Day 2",
    "section": "11.26-11.32 : Archive scope",
    "text": "11.26-11.32 : Archive scope\nUpdate CHANGELOG.md and CITATION.cff, set up sync on Zenodo, then created a Git release."
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#look-over-code",
    "href": "logbook/posts/2024_07_29/index.html#look-over-code",
    "title": "Day 2",
    "section": "12.50-12.56: Look over code",
    "text": "12.50-12.56: Look over code\nREADME:\n\nDirects to NAASP_DES_Example_Script.R which provides walk through example for running model.\nNotes the repository contains code for two papers - we are interested in NAAASP_COVID (rather than SWAN)\n\nCopied the items relevant to NAAASP COVID into reproduction/. As README states results are saved to output/, create a placeholder output folder\nThe models/ folder seems to contain scripts to run each of the scenarios."
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#set-up-environment",
    "href": "logbook/posts/2024_07_29/index.html#set-up-environment",
    "title": "Day 2",
    "section": "12.57-13.04: Set up environment",
    "text": "12.57-13.04: Set up environment\nBased on experience trying to backdate R and packages in my previous reproduction (Huang et al. 2019), I decided that this time I would start with the latest R and packages, and then backdate if its not working.\nThis means using R 4.4.1 (paper mentions 3.6.3).\nAt the start of each script, it lists the packages to be installed (though not versions). Created a DESCRIPTION file with these packages.\nTitle: Computational reproducibility assessment of Kim et al. 2019\nDepends: \n    R\nImports:\n    Rcpp,\n    expm,\n    msm,\n    foreach,\n    iterators,\n    doParallel\nRan:\nrenv::init(bare=TRUE)\nrenv::install()\nrenv::snapshot()"
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#trying-to-run-model",
    "href": "logbook/posts/2024_07_29/index.html#trying-to-run-model",
    "title": "Day 2",
    "section": "13.05-13.13, 13.48-13.55, 14.07-14.21, 14.53-15.08: Trying to run model",
    "text": "13.05-13.13, 13.48-13.55, 14.07-14.21, 14.53-15.08: Trying to run model\nTried running run_aaamodel_65yo_scen0.R. Had error:\nthis.dir &lt;- dirname(parent.frame(2)$ofile)\nError in dirname(parent.frame(2)$ofile) : \n  a character vector argument expected\nRealised this has a comment above stating:\n# Set the working directory to the root directory of AAA_DES_model (can only run this if sourcing the file)\nSo instead tried running with Source - this worked, up until this line:\n&gt; v1other\npostSurgeryInitialPeriod = 0.08213552 \ntimeToMonitoringFollowingOpenSurgery = 0.1149897 \ntimeBetweenMonitoringFollowingEvarSurgery = 1 \nzeroGrowthDiameterThreshold = 2 \nbaselineDiameters = data.frame with 2 columns:\n  size = 0.7 0.8 0.9 1 1.1 1.2 1.3 1.4 ...\n  weight = 2.86e-06 5.71e-06 4.43e-05 0.000351429 0.001205714 0.005032857 0.017921429 0.045698572 ...\nprevalenceThreshold = 3 \naortaDiameterThresholds = list: =Error in cat(names(element)[i], \"=\", element[[i]], \" \", sep = \"\") : \n  argument 3 (type 'list') cannot be handled by 'cat'\nv1other was created when we called source(\"input/NAAASP_Men_2020-05-11/DES_Data_Input_NAAASP_Men_30years_time_horizon_2020-05-11.R\"). Looking at that script, aortaDiameterThresholds are set as v1other$aortaDiameterThresholds &lt;- list(c(3.0, 4.5, 5.5)). Viewing the object rather than printing it with View(v1other), I can see that the thresholds are stored, but its just a list within a list.\nI tried commenting the print statement in run_aaamodel... but this just led to a later error for the same variable when it is used. As such, I instead altered assignment of this variable in the sourced script to c(3.0, 4.5, 5.5) (removing list()).\nThis then ran without issue. As it ran, I can see it sets a random seed (set.seed(3210)). As per usual, paused timing while it ran.\nSpent a long while on processPersons() (scen0.invite &lt;- processPersons(v0, v1other, v2, personData.screen)). At 13.48 (with model running since 13.13), I could see these would likely be slow models to run, so logged into the remote computer, cloned the GitHub repository there, and ran the next script starting at 13.55, run_aaamodel_65yo_scen0.R. To do so, after cloning, I ran:\ncd stars-reproduce-kim-2021/reproduction\nRscript -e \"renv::restore()\"\nRscript -e \"source('models/NAAASP_COVID_modelling/run_aaamodel_65yo_scen1.R')\"\n\n\n\n\n\n\nReflection\n\n\n\nIncluding the expected run time would be handy, as I assume this is working fine, but that’s working on the assumption that these models take a long time to run (which I’m not sure yet whether that is the case or not).\nIn this case, as I later found out they used HPC, it would’ve been beneficial to mention that also!\n\n\nI checked the run_aaamodel... scripts and realised that in each, none were using parallel processing (as v0$method &lt;- \"serial\").\nLooking at the DES_Model code I can see the example of processPersons() allows three possible inputs:\n\n“serial”\n“parallel” (which uses parallel)\n“foreach” (which uses doParallel)\n\nThe function psa() is the same, but also includes “parallelBatches” alongside “foreach”. However, the consequence of those inputs is to return an error that the method has not been implemented for psa. Hence, psa can only run with “serial” or “parallel”. Likewise for psaAboveDiagnosisThreshold().\nAt 14.16 (so having let the model run since 13.55, for 21 minutes), I cancelled the run on the remote computer, and altered the scenario script to set v0$method &lt;- \"parallel\". Then set that running, starting at 14.21. At this moment, the first scenario was still running on my machine (since 13.13, so for apx. 1h 10m now).\nAt 14.39, I noticed the parallel model said Killed. In case I might have accidentally done this, I just set it to rerun again. However, at 14.52, it showed as Killed again. Upon Googling, I can see this message occurs when you run out of memory - which perhaps, might be why all were set to run sequentially, if its too intensive to run in parallel. I switched it back to “serial”.\nHowever, the model still running on my machine has now been going for 1h 42m. Having looked in the repository and article for any indication of runtime or requirement of HPC, I’ve yet to find anything. I tried looking now at the article first describing the model (https://doi.org/10.1177/0272989X17753380). In this article, they state the run time:\nHowever, the computational requirements of the DES were extensive, given the number of individuals needed to reduce sampling variation to an acceptable level and characterizing uncertainty through PSA. Run time was in the region of 24 h to run the model with 500,000 patients and 1,000 PSA iterations, even with parallelization and the use of a high-powered computer.\nIn this case, “each scenario model is run for 10 million hypothetical individuals randomly drawn with replacement from the distribution of the relevant population. The models are run for a period of 30 years”. However, as there is no mention of performing probabilistic sensitivity analysis iterations in the article, we could expect this to be quicker than that (although note it is 10m patients instead of 500k).\nDiscussed with Tom and agreed to:\n\n\nTry and just run it with very few people, just so we can see if the model is working, and whether we could get similar results with fewer people in the model\n\n\nTry and run it sequentially on the remote computer overnight"
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#running-the-model-with-fewer-people",
    "href": "logbook/posts/2024_07_29/index.html#running-the-model-with-fewer-people",
    "title": "Day 2",
    "section": "15.09-15.42: Running the model with fewer people",
    "text": "15.09-15.42: Running the model with fewer people\nDES_Input_Definitions states that the number of people to run through the DES is defined by v0$numberOfPersons, default 1000. Can see in run_aaamodel_65yo_scen0.R that it has been set to v0$numberOfPersons &lt;- 1e7. I replaced this with v0$numberOfPersons &lt;- 1000. This finished almost immediately, then hit an error:\n&gt; TableOfCounts(scen0.invite, v1other)\nError in \"screen\" %in% eventHistory$events && !(\"nonvisualization\" %in%  : \n  'length = 3' in coercion to 'logical(1)'\nTableOfCounts() is from DES_Model.R. Working through each line of the function, I found that the error is occurring for scre_dropout=countDropouts(result, v1other).\nIn this function, personsInfo (result, ie. scen0.invite) is used. It loops through the EventHistories for each person: for (i in 1:length(personsInfo$eventHistories)). It checks whether their events:\n\nIncludes “screen” (\"screen\" %in% eventHistory$events)\nDoes not include “nonvisualization” (!(\"nonvisualization\" %in% eventHistory$events))\nIf the measured size for screen is greater than or equal to v1other$aortaDiameterThresholds[[1]]\n\nThe error occurs for that final comparison. That is the item we had to change earlier to be able to get the model to run. I tried setting that back to being a list within a list - v1other$aortaDiameterThresholds &lt;- list(c(3.0, 4.5, 5.5)). However, I realised that caused the issue, and that in fact, run_aaamodel_65yo_scen0.R is changing it to list() again before running the model:\n## Change v1other$aortaDiameterThresholds to be a list (new syntax)\nv1other$aortaDiameterThresholds &lt;- list(v1other$aortaDiameterThresholds)\nIf I comment out that line, an error occurs. Hence, it seems we require it to be in a list within a list for the model, but just a list for TableOfCounts(). Looking at all the repository code, the reason becomes apparent in models/NAASP_COVID_modelling/run_aaamodel_surv_scen3.R, when multiple aaortaDiameterThresholds are provided.\nAs such, I set about modifying the later processing functions so that they are able to use this list() format:\n\ninput/NAAASP_Men_2020-05-11/DES_Data_Input_NAAASP_Men_30years_time_horizon_2020-05-11.R: returned back to list(c()), but then changed run_aaamodel_65yo_scen0.R to not add an additional list() over the top.\nDES_Model.R: countDropouts(): &gt;= v1other$aortaDiameterThresholds[[1]] to &gt;= v1other$aortaDiameterThresholds[[1]][1]\n\nThe whole script then ran successfully!\n\n\n\n\n\n\nReflection\n\n\n\nThese errors will likely be the result of having modified code but no re-run everything from scratch (unsurprising given the anticipated model run times)."
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#inspecting-outcome-from-a-model-run",
    "href": "logbook/posts/2024_07_29/index.html#inspecting-outcome-from-a-model-run",
    "title": "Day 2",
    "section": "15.43-16.00, 16.03-16.43, 16.45-16.47, 16.53-16.56: Inspecting outcome from a model run",
    "text": "15.43-16.00, 16.03-16.43, 16.45-16.47, 16.53-16.56: Inspecting outcome from a model run\nThat R script ran the status quo (I0) scenario for invited 65 year olds. The parameters from Table 1 are below, along with their location in the data from DES_Input_Definitions.xlsx\n\nAttendance 75% - v2$probOfAttendScreen\nDrop-out rate/annum: 6% - v2$rateOfDropoutFromMonitoring\nThreshold for surgery: 5.5cm - v1other$aortaDiameterThresholds[[1]][3] (“These are the aortic cut-points where surveillance intervals change. Note, the first cut-point must always relate to the aortic size where individuals enter the AAA surveillance programme (e.g. 3.0cm). The last cut-point must always relate to the aortic size where surgery is to be considered (e.g. 5.5cm)”)\n\nLooking at the next R script, run_aaamodel_65yo_scen1.R, I can see that they repeat the model multiple times to get results from varying parameters of that scenario. That script is scenario 1 which, from Table 1, we can see delays invitation from 3 months to 5 years.\nI switched to trying that script, but again first setting:\n\n# v1other$aortaDiameterThresholds &lt;- list(v1other$aortaDiameterThresholds)\nv0$numberOfPersons &lt;- 1000\n\nThis ran eight “scenarios” within the script. The output dataframe scen1summaryi showed the results from each of those eight variants. I add a line to the script to save this to csv. However, I could see that the number dead was 7 or 8 across all scenarios, so we likely did need to up the number in the model a bit more to start getting some real results.\n\nimport pandas as pd\n\nres = pd.read_csv('output_65yo_scen1_n1000.csv')\nres[['delayscr', 'aaadead']].sort_values(by='delayscr')\n\n\n\n\n\n\n\n\ndelayscr\naaadead\n\n\n\n\n7\n0.00\n7\n\n\n0\n0.25\n7\n\n\n1\n0.50\n7\n\n\n2\n1.00\n7\n\n\n3\n2.00\n7\n\n\n4\n3.00\n7\n\n\n5\n4.00\n8\n\n\n6\n5.00\n8\n\n\n\n\n\n\n\nI increased it to 10,000 patients. For each of the eight runs in the script, it took about 27 seconds (so under four minutes in total). Here we start to see more change between each scenario, and it becomes more feasible to look at the results.\n\nimport pandas as pd\n\nres = pd.read_csv('output_65yo_scen1_n10000.csv')\nres[['delayscr', 'aaadead', 'emeropen']].sort_values(by='delayscr')\n\n\n\n\n\n\n\n\ndelayscr\naaadead\nemeropen\n\n\n\n\n7\n0.00\n96\n33\n\n\n0\n0.25\n96\n33\n\n\n1\n0.50\n98\n32\n\n\n2\n1.00\n96\n31\n\n\n3\n2.00\n98\n31\n\n\n4\n3.00\n98\n32\n\n\n5\n4.00\n101\n32\n\n\n6\n5.00\n103\n32\n\n\n\n\n\n\n\nEach result here relates to Table 2 (i.e. excess AAA deaths, and excess emergency operations). To calculate excess, given that the results appears to increment from the first 0 scenario, I’m assuming that this is the change in deaths from the 0 scenario.\nI created an .Rmd file to start processing the results. This required the addition of rmarkdown to the renv. I add dplyr for processing the results. Looking at excess deaths, we can see the anticipated pattern, although for emergency operations, the numbers are still too small that they fluctuate, and emergency operations goes in the wrong direction.\n\nimport pandas as pd\n\npd.read_csv('tab2.csv')\n\n\n\n\n\n\n\n\ndelayscr\nexcess_death\nexcess_op\n\n\n\n\n0\n0.00\n0\n0\n\n\n1\n0.25\n0\n0\n\n\n2\n0.50\n2\n-1\n\n\n3\n1.00\n0\n-2\n\n\n4\n2.00\n2\n-2\n\n\n5\n3.00\n2\n-1\n\n\n6\n4.00\n5\n-1\n\n\n7\n5.00\n7\n-1\n\n\n\n\n\n\n\nI tried upping it to 100,000 people, and recorded the time with different settings:\n\n“serial” - 5 minutes 7 seconds\n“parallel” - 2 minutes 12 seconds - so estimated 17 and a half minutes in total\n“foreach” - not possible, Error in processPersons(v0, v1other, v2, personData.screen) : v0$randomSeed does not yet work with v0$method=\"foreach\"\n\nFor each of these, about 45 seconds is results processing at the end (e.g. Eventsandcosts())\nWhilst these ran, I looked through the repository to try and spot whether they had functions to generate the plots from the article. I found plotting functions in DES_Model.R, shiny_output_functions.R and NAAASP_DES_Example_Script.R, though none relevant to the article, so it appears I’ll need to write the code to do that processing."
  },
  {
    "objectID": "logbook/posts/2024_07_29/index.html#timings",
    "href": "logbook/posts/2024_07_29/index.html#timings",
    "title": "Day 2",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 32\n\n# Times from today\ntimes = [\n    ('09.38', '09.43'),\n    ('09.53', '09.55'),\n    ('10.05', '10.15'),\n    ('10.29', '10.45'),\n    ('10.46', '11.02'),\n    ('11.09', '11.13'),\n    ('11.26', '11.32'),\n    ('12.50', '12.56'),\n    ('12.57', '13.04'),\n    ('13.05', '13.13'), \n    ('13.48', '13.55'),\n    ('14.07', '14.21'),\n    ('14.53', '15.08'),\n    ('15.09', '15.42'),\n    ('15.43', '16.00'),\n    ('16.03', '16.43'),\n    ('16.45', '16.47'),\n    ('16.53', '16.56')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 211m, or 3h 31m\nTotal used to date: 243m, or 4h 3m\nTime remaining: 2157m, or 35h 57m\nUsed 10.1% of 40 hours max"
  },
  {
    "objectID": "evaluation/badges.html",
    "href": "evaluation/badges.html",
    "title": "Journal badges",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed, so all criteria are currently set as unmet (❌)\nThis page evaluates the extent to which the author-published research artefacts meet the criteria of badges related to reproducibility from various organisations and journals.\nCaveat: Please note that these criteria are based on available information about each badge online, and that we have likely differences in our procedure (e.g. allowed troubleshooting for execution and reproduction, not under tight time pressure to complete). Moreover, we focus only on reproduction of the discrete-event simulation, and not on other aspects of the article. We cannot guarantee that the badges below would have been awarded in practice by these journals."
  },
  {
    "objectID": "evaluation/badges.html#criteria",
    "href": "evaluation/badges.html#criteria",
    "title": "Journal badges",
    "section": "Criteria",
    "text": "Criteria\n\n\nCode\nfrom IPython.display import display, Markdown\nimport numpy as np\nimport pandas as pd\n\n# Criteria and their definitions\ncriteria = {\n    'archive': 'Stored in a permanent archive that is publicly and openly accessible',\n    'id': 'Has a persistent identifier',\n    'license': 'Includes an open license',\n    'relevant': '''Artefacts are relevant to and contribute to the article's results''',\n    'complete': 'Complete set of materials shared (as would be needed to fully reproduce article)',\n    'structure': 'Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)',\n    'documentation_sufficient': 'Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)',\n    'documentation_careful': 'Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)',\n    # This criteria is kept seperate to documentation_careful, as it specifically requires a README file\n    'documentation_readme': 'Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript',\n    'execute': 'Scripts can be successfully executed',\n    'regenerated': 'Independent party regenerated results using the authors research artefacts',\n    'hour': 'Reproduced within approximately one hour (excluding compute time)',\n}\n\n# Evaluation for this study\n# TODO: Complete evaluate for each criteria\neval = pd.Series({\n    'archive': 0,\n    'id': 0,\n    'license': 0,\n    'relevant': 0,\n    'complete': 0,\n    'structure': 0,\n    'documentation_sufficient': 0,\n    'documentation_careful': 0,\n    'documentation_readme': 0,\n    'execute': 0,\n    'regenerated': 0,\n    'hour': 0,\n})\n\n# Get list of criteria met (True/False) overall\neval_list = list(eval)\n\n# Define function for creating the markdown formatted list of criteria met\ndef create_criteria_list(criteria_dict):\n    '''\n    Creates a string which contains a Markdown formatted list with icons to\n    indicate whether each criteria was met\n\n    Parameters:\n    -----------\n    criteria_dict : dict\n        Dictionary where keys are the criteria (variable name) and values are\n        Boolean (True/False of whether this study met the criteria)\n\n    Returns:\n    --------\n    formatted_list : string\n        Markdown formatted list\n    '''\n    callout_icon = {True: '✅',\n                    False: '❌'}\n    # Create list with...\n    formatted_list = ''.join([\n        '* ' +\n        callout_icon[eval[key]] + # Icon based on whether it met criteria\n        ' ' +\n        value + # Full text description of criteria\n        '\\n' for key, value in criteria_dict.items()])\n    return(formatted_list)\n\n# Define groups of criteria\ncriteria_share_how = ['archive', 'id', 'license']\ncriteria_share_what = ['relevant', 'complete']\ncriteria_doc_struc = ['structure', 'documentation_sufficient', 'documentation_careful', 'documentation_readme']\ncriteria_run = ['execute', 'regenerated', 'hour']\n\n# Create text section\ndisplay(Markdown(f'''\nTo assess whether the author's materials met the requirements of each badge, a list of criteria was produced. Between each badge (and between categories of badge), there is often alot of overlap in criteria.\n\nThis study met **{sum(eval_list)} of the {len(eval_list)}** unique criteria items. These were as follows:\n\nCriteria related to how artefacts are shared -\n\n{create_criteria_list({k: criteria[k] for k in criteria_share_how})}\n\nCriteria related to what artefacts are shared -\n\n{create_criteria_list({k: criteria[k] for k in criteria_share_what})}\n\nCriteria related to the structure and documentation of the artefacts -\n\n{create_criteria_list({k: criteria[k] for k in criteria_doc_struc})}\n\nCriteria related to running and reproducing results -\n\n{create_criteria_list({k: criteria[k] for k in criteria_run})}\n'''))\n\n\nTo assess whether the author’s materials met the requirements of each badge, a list of criteria was produced. Between each badge (and between categories of badge), there is often alot of overlap in criteria.\nThis study met 0 of the 12 unique criteria items. These were as follows:\nCriteria related to how artefacts are shared -\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n\nCriteria related to what artefacts are shared -\n\n❌ Artefacts are relevant to and contribute to the article’s results\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n\nCriteria related to the structure and documentation of the artefacts -\n\n❌ Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌ Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)\n❌ Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript\n\nCriteria related to running and reproducing results -\n\n❌ Scripts can be successfully executed\n❌ Independent party regenerated results using the authors research artefacts\n❌ Reproduced within approximately one hour (excluding compute time)"
  },
  {
    "objectID": "evaluation/badges.html#badges",
    "href": "evaluation/badges.html#badges",
    "title": "Journal badges",
    "section": "Badges",
    "text": "Badges\n\n\nCode\n# Full badge names\nbadge_names = {\n    # Open objects\n    'open_niso': 'NISO \"Open Research Objects (ORO)\"',\n    'open_niso_all': 'NISO \"Open Research Objects - All (ORO-A)\"',\n    'open_acm': 'ACM \"Artifacts Available\"',\n    'open_cos': 'COS \"Open Code\"',\n    'open_ieee': 'IEEE \"Code Available\"',\n    # Object review\n    'review_acm_functional': 'ACM \"Artifacts Evaluated - Functional\"',\n    'review_acm_reusable': 'ACM \"Artifacts Evaluated - Reusable\"',\n    'review_ieee': 'IEEE \"Code Reviewed\"',\n    # Results reproduced\n    'reproduce_niso': 'NISO \"Results Reproduced (ROR-R)\"',\n    'reproduce_acm': 'ACM \"Results Reproduced\"',\n    'reproduce_ieee': 'IEEE \"Code Reproducible\"',\n    'reproduce_psy': 'Psychological Science \"Computational Reproducibility\"'\n}\n\n# Criteria required by each badge\nbadges = {\n    # Open objects\n    'open_niso': ['archive', 'id', 'license'],\n    'open_niso_all': ['archive', 'id', 'license', 'complete'],\n    'open_acm': ['archive', 'id'],\n    'open_cos': ['archive', 'id', 'license', 'complete', 'documentation_sufficient'],\n    'open_ieee': ['complete'],\n    # Object review\n    'review_acm_functional': ['documentation_sufficient', 'relevant', 'complete', 'execute'],\n    'review_acm_reusable': ['documentation_sufficient', 'documentation_careful', 'relevant', 'complete', 'execute', 'structure'],\n    'review_ieee': ['complete', 'execute'],\n    # Results reproduced\n    'reproduce_niso': ['regenerated'],\n    'reproduce_acm': ['regenerated'],\n    'reproduce_ieee': ['regenerated'],\n    'reproduce_psy': ['regenerated', 'hour', 'structure', 'documentation_readme'],\n}\n\n# Identify which badges would be awarded based on criteria\n# Get list of badges met (True/False) overall\naward = {}\nfor badge in badges:\n    award[badge] = all([eval[key] == 1 for key in badges[badge]])\naward_list = list(award.values())\n\n# Write introduction\n# Get list of badges met (True/False) by category\naward_open = [v for k,v in award.items() if k.startswith('open_')]\naward_review = [v for k,v in award.items() if k.startswith('review_')]\naward_reproduce = [v for k,v in award.items() if k.startswith('reproduce_')]\n\n# Create and display text for introduction\ndisplay(Markdown(f'''\nIn total, the original study met the criteria for **{sum(award_list)} of the {len(award_list)} badges**. This included:\n\n* **{sum(award_open)} of the {len(award_open)}** “open objects” badges\n* **{sum(award_review)} of the {len(award_review)}** “object review” badges\n* **{sum(award_reproduce)} of the {len(award_reproduce)}** “reproduced” badges\n'''))\n\n# Make function that creates collapsible callouts for each badge\ndef create_badge_callout(award_dict):\n    '''\n    Displays Markdown callouts created for each badge in the dictionary, showing\n    whether the criteria for that badge was met.\n\n    Parameters:\n    -----------\n    award_dict : dict\n        Dictionary where key is badge (as variable name), and value is Boolean\n        (whether badge is awarded)\n    '''\n    callout_appearance = {True: 'tip',\n                          False: 'warning'}\n    callout_icon = {True: '✅',\n                    False: '❌'}\n    callout_text = {True: 'Meets all criteria:',\n                    False: 'Does not meet all criteria:'}\n\n    for key, value in award_dict.items():\n        # Create Markdown list with...\n        criteria_list = ''.join([\n            '* ' +\n            callout_icon[eval[k]] + # Icon based on whether it met criteria\n            ' ' +\n            criteria[k] + # Full text description of criteria\n            '\\n' for k in badges[key]])\n        # Create the callout and display it\n        display(Markdown(f'''\n::: {{.callout-{callout_appearance[value]} appearance=\"minimal\" collapse=true}}\n\n## {callout_icon[value]} {badge_names[key]}\n\n{callout_text[value]}\n\n{criteria_list}\n:::\n'''))\n\n# Create badge functions with introductions and callouts\ndisplay(Markdown('''\n### \"Open objects\" badges\n\nThese badges relate to research artefacts being made openly available.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('open_')})\n\ndisplay(Markdown('''\n### \"Object review\" badges\n\nThese badges relate to the research artefacts being reviewed against criteria of the badge issuer.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('review_')})\n\ndisplay(Markdown('''\n### \"Reproduced\" badges\n\nThese badges relate to an independent party regenerating the reuslts of the article using the author objects.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('reproduce_')})\n\n\nIn total, the original study met the criteria for 0 of the 12 badges. This included:\n\n0 of the 5 “open objects” badges\n0 of the 3 “object review” badges\n0 of the 4 “reproduced” badges\n\n\n\n“Open objects” badges\nThese badges relate to research artefacts being made openly available.\n\n\n\n\n\n\n\n\n❌ NISO “Open Research Objects (ORO)”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n\n\n\n\n\n\n\n\n\n\n\n\n❌ NISO “Open Research Objects - All (ORO-A)”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n\n\n\n\n\n\n\n\n\n\n\n\n❌ ACM “Artifacts Available”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n\n\n\n\n\n\n\n\n\n\n\n\n❌ COS “Open Code”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Stored in a permanent archive that is publicly and openly accessible\n❌ Has a persistent identifier\n❌ Includes an open license\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n\n\n\n\n\n\n\n\n\n\n\n\n❌ IEEE “Code Available”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n\n\n\n\n\n\n“Object review” badges\nThese badges relate to the research artefacts being reviewed against criteria of the badge issuer.\n\n\n\n\n\n\n\n\n❌ ACM “Artifacts Evaluated - Functional”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌ Artefacts are relevant to and contribute to the article’s results\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n❌ Scripts can be successfully executed\n\n\n\n\n\n\n\n\n\n\n\n\n❌ ACM “Artifacts Evaluated - Reusable”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)\n❌ Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated - e.g. changing parameters, reusing for own purpose)\n❌ Artefacts are relevant to and contribute to the article’s results\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n❌ Scripts can be successfully executed\n❌ Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n\n\n\n\n\n\n\n\n\n\n\n\n❌ IEEE “Code Reviewed”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Complete set of materials shared (as would be needed to fully reproduce article)\n❌ Scripts can be successfully executed\n\n\n\n\n\n\n“Reproduced” badges\nThese badges relate to an independent party regenerating the reuslts of the article using the author objects.\n\n\n\n\n\n\n\n\n❌ NISO “Results Reproduced (ROR-R)”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n❌ ACM “Results Reproduced”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n❌ IEEE “Code Reproducible”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n❌ Psychological Science “Computational Reproducibility”\n\n\n\n\n\nDoes not meet all criteria:\n\n❌ Independent party regenerated results using the authors research artefacts\n❌ Reproduced within approximately one hour (excluding compute time)\n❌ Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n❌ Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript"
  },
  {
    "objectID": "evaluation/badges.html#sources",
    "href": "evaluation/badges.html#sources",
    "title": "Journal badges",
    "section": "Sources",
    "text": "Sources\nNational Information Standards Organisation (NISO) (NISO Reproducibility Badging and Definitions Working Group (2021))\n\n“Open Research Objects (ORO)”\n“Open Research Objects - All (ORO-A)”\n“Results Reproduced (ROR-R)”\n\nAssociation for Computing Machinery (ACM) (Association for Computing Machinery (ACM) (2020))\n\n“Artifacts Available”\n“Artifacts Evaluated - Functional”\n“Artifacts Evaluated - Resuable”\n“Results Reproduced”\n\nCenter for Open Science (COS) (Blohowiak et al. (2023))\n\n“Open Code”\n\nInstitute of Electrical and Electronics Engineers (IEEE) (Institute of Electrical and Electronics Engineers (IEEE) (n.d.))\n\n“Code Available”\n“Code Reviewed”\n“Code Reproducible”\n\nPsychological Science (Hardwicke and Vazire (2023) and Association for Psychological Science (APS) (2023))\n\n“Computational Reproducibility”"
  },
  {
    "objectID": "quarto_site/license.html",
    "href": "quarto_site/license.html",
    "title": "Open Source License",
    "section": "",
    "text": "This repository is licensed under the [license].\n\n\n\n\n\n\nView license\n\n\n\n\n\n               GNU LESSER GENERAL PUBLIC LICENSE\n                   Version 3, 29 June 2007\nCopyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/ Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\nThis version of the GNU Lesser General Public License incorporates the terms and conditions of version 3 of the GNU General Public License, supplemented by the additional permissions listed below.\n\nAdditional Definitions.\n\nAs used herein, “this License” refers to version 3 of the GNU Lesser General Public License, and the “GNU GPL” refers to version 3 of the GNU General Public License.\n“The Library” refers to a covered work governed by this License, other than an Application or a Combined Work as defined below.\nAn “Application” is any work that makes use of an interface provided by the Library, but which is not otherwise based on the Library. Defining a subclass of a class defined by the Library is deemed a mode of using an interface provided by the Library.\nA “Combined Work” is a work produced by combining or linking an Application with the Library. The particular version of the Library with which the Combined Work was made is also called the “Linked Version”.\nThe “Minimal Corresponding Source” for a Combined Work means the Corresponding Source for the Combined Work, excluding any source code for portions of the Combined Work that, considered in isolation, are based on the Application, and not on the Linked Version.\nThe “Corresponding Application Code” for a Combined Work means the object code and/or source code for the Application, including any data and utility programs needed for reproducing the Combined Work from the Application, but excluding the System Libraries of the Combined Work.\n\nException to Section 3 of the GNU GPL.\n\nYou may convey a covered work under sections 3 and 4 of this License without being bound by section 3 of the GNU GPL.\n\nConveying Modified Versions.\n\nIf you modify a copy of the Library, and, in your modifications, a facility refers to a function or data to be supplied by an Application that uses the facility (other than as an argument passed when the facility is invoked), then you may convey a copy of the modified version:\n\nunder this License, provided that you make a good faith effort to ensure that, in the event an Application does not supply the function or data, the facility still operates, and performs whatever part of its purpose remains meaningful, or\nunder the GNU GPL, with none of the additional permissions of this License applicable to that copy.\n\n\nObject Code Incorporating Material from Library Header Files.\n\nThe object code form of an Application may incorporate material from a header file that is part of the Library. You may convey such object code under terms of your choice, provided that, if the incorporated material is not limited to numerical parameters, data structure layouts and accessors, or small macros, inline functions and templates (ten or fewer lines in length), you do both of the following:\n\nGive prominent notice with each copy of the object code that the Library is used in it and that the Library and its use are covered by this License.\nAccompany the object code with a copy of the GNU GPL and this license document.\n\n\nCombined Works.\n\nYou may convey a Combined Work under terms of your choice that, taken together, effectively do not restrict modification of the portions of the Library contained in the Combined Work and reverse engineering for debugging such modifications, if you also do each of the following:\n\nGive prominent notice with each copy of the Combined Work that the Library is used in it and that the Library and its use are covered by this License.\nAccompany the Combined Work with a copy of the GNU GPL and this license document.\nFor a Combined Work that displays copyright notices during execution, include the copyright notice for the Library among these notices, as well as a reference directing the user to the copies of the GNU GPL and this license document.\nDo one of the following:\n\nConvey the Minimal Corresponding Source under the terms of this License, and the Corresponding Application Code in a form suitable for, and under terms that permit, the user to recombine or relink the Application with a modified version of the Linked Version to produce a modified Combined Work, in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source.\nUse a suitable shared library mechanism for linking with the Library. A suitable mechanism is one that (a) uses at run time a copy of the Library already present on the user’s computer system, and (b) will operate properly with a modified version of the Library that is interface-compatible with the Linked Version.\n\nProvide Installation Information, but only if you would otherwise be required to provide such information under section 6 of the GNU GPL, and only to the extent that such information is necessary to install and execute a modified version of the Combined Work produced by recombining or relinking the Application with a modified version of the Linked Version. (If you use option 4d0, the Installation Information must accompany the Minimal Corresponding Source and Corresponding Application Code. If you use option 4d1, you must provide the Installation Information in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source.)\n\n\nCombined Libraries.\n\nYou may place library facilities that are a work based on the Library side by side in a single library together with other library facilities that are not Applications and are not covered by this License, and convey such a combined library under terms of your choice, if you do both of the following:\n\nAccompany the combined library with a copy of the same work based on the Library, uncombined with any other library facilities, conveyed under the terms of this License.\nGive prominent notice with the combined library that part of it is a work based on the Library, and explaining where to find the accompanying uncombined form of the same work.\n\n\nRevised Versions of the GNU Lesser General Public License.\n\nThe Free Software Foundation may publish revised and/or new versions of the GNU Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Library as you received it specifies that a certain numbered version of the GNU Lesser General Public License “or any later version” applies to it, you have the option of following the terms and conditions either of that published version or of any later version published by the Free Software Foundation. If the Library as you received it does not specify a version number of the GNU Lesser General Public License, you may choose any version of the GNU Lesser General Public License ever published by the Free Software Foundation.\nIf the Library as you received it specifies that a proxy can decide whether future versions of the GNU Lesser General Public License shall apply, that proxy’s public statement of acceptance of any version is permanent authorization for you to choose that version for the Library.\n\n\n\n\nThis is aligned with the original study, who shared their code under [license].\n\n\n\n\n\n\nView license\n\n\n\n\n\n\n[Embedded license]\n\n\n\n\nThe original study was published in the journal “[Journal name]”. They distributed the article under [Add more details about license]\n\n\n\n\n\n\nView copyright statement from journal"
  },
  {
    "objectID": "logbook/posts/2024_07_26/index.html",
    "href": "logbook/posts/2024_07_26/index.html",
    "title": "Day 1",
    "section": "",
    "text": "Note\n\n\n\nSet-up repository and upload materials. Total time used: 0h 32m (1.3%)"
  },
  {
    "objectID": "logbook/posts/2024_07_26/index.html#set-up-repository",
    "href": "logbook/posts/2024_07_26/index.html#set-up-repository",
    "title": "Day 1",
    "section": "15.58-16.03, 16.21-16.30: Set-up repository",
    "text": "15.58-16.03, 16.21-16.30: Set-up repository\n\nCreate repository from template\nSet up environment\nModified template files:\n\nREADME.md\nquarto site index.qmd\nCITATION.cff\n_quarto.yml\n\nSet up site on GitHub pages (quarto publish gh-pages)"
  },
  {
    "objectID": "logbook/posts/2024_07_26/index.html#upload-code-and-update-license",
    "href": "logbook/posts/2024_07_26/index.html#upload-code-and-update-license",
    "title": "Day 1",
    "section": "16.36-16.41: Upload code and update license",
    "text": "16.36-16.41: Upload code and update license\nModel code is available at: https://github.com/mikesweeting/AAA_DES_model\nIt is available under an LGPL-3.0 license, so I updated this repository to use the same license (GNU LESSER GENERAL PUBLIC LICENSE Version 3). This license requires:\n\nCopy of full license and original copyright notice\nInclude source code when distribute derivative work\nLicense derivative work under same license"
  },
  {
    "objectID": "logbook/posts/2024_07_26/index.html#upload-journal-article",
    "href": "logbook/posts/2024_07_26/index.html#upload-journal-article",
    "title": "Day 1",
    "section": "16.43-16.56: Upload journal article",
    "text": "16.43-16.56: Upload journal article\nThe article is published with PLoS ONE and has a permissive copyright statement:\n\n“Copyright: © 2021 Kim et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.”\n\nhttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253327\nHence, uploaded article, figures, tables and supplementary materials to original_study/. Converted .tif files to .png (e.g. convert sup3.tif sup3.png). Converted .docx to .pdf (libreoffice --headless --convert-to pdf sup1.docx --outdir sup1.pdf).\nAmended study_publication.qmd to display these.\nAdd the study to references.bib."
  },
  {
    "objectID": "logbook/posts/2024_07_26/index.html#timings",
    "href": "logbook/posts/2024_07_26/index.html#timings",
    "title": "Day 1",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 0\n\n# Times from today\ntimes = [\n    ('15.58', '16.03'),\n    ('16.21', '16.30'),\n    ('16.36', '16.41'),\n    ('16.43', '16.56')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 32m, or 0h 32m\nTotal used to date: 32m, or 0h 32m\nTime remaining: 2368m, or 39h 28m\nUsed 1.3% of 40 hours max"
  },
  {
    "objectID": "quarto_site/study_publication.html",
    "href": "quarto_site/study_publication.html",
    "title": "Publication",
    "section": "",
    "text": "Kim et al. (2021)"
  },
  {
    "objectID": "quarto_site/study_publication.html#code-and-data",
    "href": "quarto_site/study_publication.html#code-and-data",
    "title": "Publication",
    "section": "Code and data",
    "text": "Code and data\nCopied into this repository: https://github.com/pythonhealthdatascience/stars-reproduce-kim-2021/tree/main/original_study/AAA_DES_model\nOriginal repository link: https://github.com/mikesweeting/AAA_DES_model"
  },
  {
    "objectID": "quarto_site/study_publication.html#journal-article",
    "href": "quarto_site/study_publication.html#journal-article",
    "title": "Publication",
    "section": "Journal article",
    "text": "Journal article\nThe article is published with PLoS ONE and has a permissive copyright statement:\n\n“Copyright: © 2021 Kim et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.”\n\nhttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253327"
  },
  {
    "objectID": "quarto_site/study_publication.html#supplementary-materials",
    "href": "quarto_site/study_publication.html#supplementary-materials",
    "title": "Publication",
    "section": "Supplementary materials",
    "text": "Supplementary materials"
  },
  {
    "objectID": "evaluation/scope.html",
    "href": "evaluation/scope.html",
    "title": "Scope",
    "section": "",
    "text": "This page outlines the parts of the journal article which we will attempt to reproduce.\nAll images and quotes on this page are sourced from Kim et al. (2021)"
  },
  {
    "objectID": "evaluation/scope.html#within-scope",
    "href": "evaluation/scope.html#within-scope",
    "title": "Scope",
    "section": "Within scope",
    "text": "Within scope\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\n\n“Fig 1. 65-year-old cohort: Change in key outcomes over varying delay to primary invitation (model I1).” Kim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nTable 2\n\n\n\n\n\n\n\n\n“Table 2. Predicted excess AAA deaths and emergency operations in the national invited 65-year-old cohort over 30y period.” Kim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\n\n\n\n“Fig 2. 65-year-old cohort: Change in key outcomes over varying attendance at primary scan (model I2).” Kim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\n\n“Fig 3. Surveillance cohort: Change in key outcomes over varying suspension of surveillance scans (model S1).” Kim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nIn-text result 1\n\n\n\n\n\nIn bold are the items not captured in Table 3 or Figure 3.\n“Suspending ultrasound scans in the surveillance cohort could result in 9 (0.4% increase) additional AAA-related deaths if scans were suspended for one year (Table 3, Fig 3). Of these, 2 (1% increase) are in the sub-group measuring 4.5–4.9 cm at the start of the pandemic and 7 (8% increase) in the sub-group measuring 5.0–5.4 cm; &lt;0.1 are in the 3.0–4.4 cm sub-group. More pronounced effects are evident for suspension for two years and beyond. Suspending surveillance for two years could result in 40 excess AAA-related deaths overall; a 1.9% increase over the lifetime of the surveillance cohort. Of these, 1 is in the 3.0–4.4 cm sub-group and 17 (7% increase) in the 4.5–4.9cm sub-group. However, the remaining 22 excess deaths are in the 5.0–5.4cm range, corresponding to a 24% increase in AAA-related deaths in this sub-group.”\n\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\n\n\n“Fig 4. Surveillance cohort: Change in key outcomes over varying dropout rates, applied for (i) 1y (model I2.1) and (ii) 2y (model I2.2).” Kim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\n\n\n\n“Fig 5. Surveillance cohort: Change in key outcomes over varying time at increased (7cm) threshold (model I3).” Kim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nTable 3\n\n\n\n\n\n\n\n\n“Table 3. Predicted excess AAA deaths and emergency operations in the national surveillance cohort over 30y period.” Kim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nSupplementary figure 3\n\n\n\n\n\n\n\n\n“S3 Fig. Cumulative impact of scenarios on surveillance cohort.” Kim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nSupplementary table 2\n\n\n\n\n\n\n\n\n“S2 Tab. Predicted excess AAA deaths and emergency operations in the national surveillance cohort over 30y period” Kim et al. (2021)"
  },
  {
    "objectID": "evaluation/scope.html#outside-scope",
    "href": "evaluation/scope.html#outside-scope",
    "title": "Scope",
    "section": "Outside scope",
    "text": "Outside scope\n\n\n\n\n\n\nTable 1\n\n\n\n\n\nInput parameters and scenarios.\n\n\n\n“Table 1. Modelled COVID policy scenarios for AAA services.” Kim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nSupplementary figure 1\n\n\n\n\n\nPart of methods (rather than a result from the model).\n\n\n\nKim et al. (2021)\n\n\n\n\n\n\n\n\n\n\n\nSupplementary figure 2\n\n\n\n\n\nPart of methods (rather than a result from the model).\n\n\n\nKim et al. (2021)"
  },
  {
    "objectID": "evaluation/reflections.html",
    "href": "evaluation/reflections.html",
    "title": "Reflections",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed\nThis page contains reflections on the facilitators and barriers to this reproduction, as well as a full list of the troubleshooting steps taken to reproduce this work."
  },
  {
    "objectID": "evaluation/reflections.html#what-would-have-helped-facilitate-this-reproduction",
    "href": "evaluation/reflections.html#what-would-have-helped-facilitate-this-reproduction",
    "title": "Reflections",
    "section": "What would have helped facilitate this reproduction?",
    "text": "What would have helped facilitate this reproduction?"
  },
  {
    "objectID": "evaluation/reflections.html#full-list-of-troubleshooting-steps",
    "href": "evaluation/reflections.html#full-list-of-troubleshooting-steps",
    "title": "Reflections",
    "section": "Full list of troubleshooting steps",
    "text": "Full list of troubleshooting steps\n\n\n\n\n\n\nView list\n\n\n\n\n\nTroubleshooting steps are grouped by theme, and the day these occurred is given in brackets at the end of each bullet."
  },
  {
    "objectID": "evaluation/artefacts.html",
    "href": "evaluation/artefacts.html",
    "title": "STARS framework",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed\nThis page evaluates the extent to which the original study meets the recommendations from the STARS framework for the sharing of code and associated materials from discrete-event simulation models (Monks, Harper, and Mustafee (2024)).\nOf the 8 essential STARS components:\n\n\nX were met fully (✅)\nX was met partially (🟡)\nX was not met (❌)\n\nOf the 5 optional STARS components:\n\n\nX was met fully (✅)\nX were not met (❌)\n\n\n\n\n\n\n\n\n\n\n\nComponent\nDescription\nMet by study?\nEvidence/location\n\n\n\n\nEssential components\n\n\n\n\n\nOpen license\nFree and open-source software (FOSS) license (e.g. MIT, GNU Public License (GPL))\n\n\n\n\nDependency management\nSpecify software libraries, version numbers and sources (e.g. dependency management tools like virtualenv, conda, poetry)\n\n\n\n\nFOSS model\nCoded in FOSS language (e.g. R, Julia, Python)\n\n\n\n\nMinimum documentation\nMinimal instructions (e.g. in README) that overview (a) what model does, (b) how to install and run model to obtain results, and (c) how to vary parameters to run new experiments\n\n\n\n\nORCID\nORCID for each study author\n\n\n\n\nCitation information\nInstructions on how to cite the research artefact (e.g. CITATION.cff file)\n\n\n\n\nRemote code repository\nCode available in a remote code repository (e.g. GitHub, GitLab, BitBucket)\n\n\n\n\nOpen science archive\nCode stored in an open science archive with FORCE11 compliant citation and guaranteed persistance of digital artefacts (e.g. Figshare, Zenodo, the Open Science Framework (OSF), and the Computational Modeling in the Social and Ecological Sciences Network (CoMSES Net))\n\n\n\n\nOptional components\n\n\n\n\n\nEnhanced documentation\nOpen and high quality documentation on how the model is implemented and works (e.g. via notebooks and markdown files, brought together using software like Quarto and Jupyter Book). Suggested content includes:• Plain english summary of project and model• Clarifying license• Citation instructions• Contribution instructions• Model installation instructions• Structured code walk through of model• Documentation of modelling cycle using TRACE• Annotated simulation reporting guidelines• Clear description of model validation including its intended purpose\n\n\n\n\nDocumentation hosting\nHost documentation (e.g. with GitHub pages, GitLab pages, BitBucket Cloud, Quarto Pub)\n\n\n\n\nOnline coding environment\nProvide an online environment where users can run and change code (e.g. BinderHub, Google Colaboratory, Deepnote)\n\n\n\n\nModel interface\nProvide web application interface to the model so it is accessible to less technical simulation users\n\n\n\n\nWeb app hosting\nHost web app online (e.g. Streamlit Community Cloud, ShinyApps hosting)\n\n\n\n\n\n\n\n\n\nReferences\n\nMonks, Thomas, Alison Harper, and Navonil Mustafee. 2024. “Towards Sharing Tools and Artefacts for Reusable Simulations in Healthcare.” Journal of Simulation 0 (0): 1–20. https://doi.org/10.1080/17477778.2024.2347882."
  },
  {
    "objectID": "evaluation/reporting.html",
    "href": "evaluation/reporting.html",
    "title": "Reporting guidelines",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed\nThis page evaluates the extent to which the journal article meets the criteria from two discrete-event simulation study reporting guidelines:"
  },
  {
    "objectID": "evaluation/reporting.html#stress-des",
    "href": "evaluation/reporting.html#stress-des",
    "title": "Reporting guidelines",
    "section": "STRESS-DES",
    "text": "STRESS-DES\nOf the 24 items in the checklist:\n\n\nX were met fully (✅)\nX were partially met (🟡)\nX were not met (❌)\nX were not applicable (N/A)\n\n\n\n\n\n\n\n\n\n\n\nItem\nRecommendation\nMet by study?\nEvidence\n\n\n\n\nObjectives\n\n\n\n\n\n1.1 Purpose of the model\nExplain the background and objectives for the model\n\n\n\n\n1.2 Model outputs\nDefine all quantitative performance measures that are reported, using equations where necessary. Specify how and when they are calculated during the model run along with how any measures of error such as confidence intervals are calculated.\n\n\n\n\n1.3 Experimentation aims\nIf the model has been used for experimentation, state the objectives that it was used to investigate.(A) Scenario based analysis – Provide a name and description for each scenario, providing a rationale for the choice of scenarios and ensure that item 2.3 (below) is completed.(B) Design of experiments – Provide details of the overall design of the experiments with reference to performance measures and their parameters (provide further details in data below).(C) Simulation Optimisation – (if appropriate) Provide full details of what is to be optimised, the parameters that were included and the algorithm(s) that was be used. Where possible provide a citation of the algorithm(s).\n\n\n\n\nLogic\n\n\n\n\n\n2.1 Base model overview diagram\nDescribe the base model using appropriate diagrams and description. This could include one or more process flow, activity cycle or equivalent diagrams sufficient to describe the model to readers. Avoid complicated diagrams in the main text. The goal is to describe the breadth and depth of the model with respect to the system being studied.\n\n\n\n\n2.2 Base model logic\nGive details of the base model logic. Give additional model logic details sufficient to communicate to the reader how the model works.\n\n\n\n\n2.3 Scenario logic\nGive details of the logical difference between the base case model and scenarios (if any). This could be incorporated as text or where differences are substantial could be incorporated in the same manner as 2.2.\n\n\n\n\n2.4 Algorithms\nProvide further detail on any algorithms in the model that (for example) mimic complex or manual processes in the real world (i.e. scheduling of arrivals/ appointments/ operations/ maintenance, operation of a conveyor system, machine breakdowns, etc.). Sufficient detail should be included (or referred to in other published work) for the algorithms to be reproducible. Pseudo-code may be used to describe an algorithm.\n\n\n\n\n2.5.1 Components - entities\nGive details of all entities within the simulation including a description of their role in the model and a description of all their attributes.\n\n\n\n\n2.5.2 Components - activities\nDescribe the activities that entities engage in within the model. Provide details of entity routing into and out of the activity.\n\n\n\n\n2.5.3 Components - resources\nList all the resources included within the model and which activities make use of them.\n\n\n\n\n2.5.4 Components - queues\nGive details of the assumed queuing discipline used in the model (e.g. First in First Out, Last in First Out, prioritisation, etc.). Where one or more queues have a different discipline from the rest, provide a list of queues, indicating the queuing discipline used for each. If reneging, balking or jockeying occur, etc., provide details of the rules. Detail any delays or capacity constraints on the queues.\n\n\n\n\n2.5.5 Components - entry/exit points\nGive details of the model boundaries i.e. all arrival and exit points of entities. Detail the arrival mechanism (e.g. ‘thinning’ to mimic a non-homogenous Poisson process or balking)\n\n\n\n\nData\n\n\n\n\n\n3.1 Data sources\nList and detail all data sources. Sources may include:• Interviews with stakeholders,• Samples of routinely collected data,• Prospectively collected samples for the purpose of the simulation study,• Public domain data published in either academic or organisational literature. Provide, where possible, the link and DOI to the data or reference to published literature.All data source descriptions should include details of the sample size, sample date ranges and use within the study.\n\n\n\n\n3.2 Pre-processing\nProvide details of any data manipulation that has taken place before its use in the simulation, e.g. interpolation to account for missing data or the removal of outliers.\n\n\n\n\n3.3 Input parameters\nList all input variables in the model. Provide a description of their use and include parameter values. For stochastic inputs provide details of any continuous, discrete or empirical distributions used along with all associated parameters. Give details of all time dependent parameters and correlation.Clearly state:• Base case data• Data use in experimentation, where different from the base case.• Where optimisation or design of experiments has been used, state the range of values that parameters can take.• Where theoretical distributions are used, state how these were selected and prioritised above other candidate distributions.\n\n\n\n\n3.4 Assumptions\nWhere data or knowledge of the real system is unavailable what assumptions are included in the model? This might include parameter values, distributions or routing logic within the model.\n\n\n\n\nExperimentation\n\n\n\n\n\n4.1 Initialisation\nReport if the system modelled is terminating or non-terminating. State if a warm-up period has been used, its length and the analysis method used to select it. For terminating systems state the stopping condition.State what if any initial model conditions have been included, e.g., pre-loaded queues and activities. Report whether initialisation of these variables is deterministic or stochastic.\n\n\n\n\n4.2 Run length\nDetail the run length of the simulation model and time units.\n\n\n\n\n4.3 Estimation approach\nState the method used to account for the stochasticity: For example, two common methods are multiple replications or batch means. Where multiple replications have been used, state the number of replications and for batch means, indicate the batch length and whether the batch means procedure is standard, spaced or overlapping. For both procedures provide a justification for the methods used and the number of replications/size of batches.\n\n\n\n\nImplementation\n\n\n\n\n\n5.1 Software or programming language\nState the operating system and version and build number.State the name, version and build number of commercial or open source DES software that the model is implemented in.State the name and version of general-purpose programming languages used (e.g. Python 3.5).Where frameworks and libraries have been used provide all details including version numbers.\n\n\n\n\n5.2 Random sampling\nState the algorithm used to generate random samples in the software/programming language used e.g. Mersenne Twister.If common random numbers are used, state how seeds (or random number streams) are distributed among sampling processes.\n\n\n\n\n5.3 Model execution\nState the event processing mechanism used e.g. three phase, event, activity, process interaction.Note that in some commercial software the event processing mechanism may not be published. In these cases authors should adhere to item 5.1 software recommendations.State all priority rules included if entities/activities compete for resources.If the model is parallel, distributed and/or use grid or cloud computing, etc., state and preferably reference the technology used. For parallel and distributed simulations the time management algorithms used. If the HLA is used then state the version of the standard, which run-time infrastructure (and version), and any supporting documents (FOMs, etc.)\n\n\n\n\n5.4 System specification\nState the model run time and specification of hardware used. This is particularly important for large scale models that require substantial computing power. For parallel, distributed and/or use grid or cloud computing, etc. state the details of all systems used in the implementation (processors, network, etc.)\n\n\n\n\nCode access\n\n\n\n\n\n6.1 Computer model sharing statement\nDescribe how someone could obtain the model described in the paper, the simulation software and any other associated software (or hardware) needed to reproduce the results. Provide, where possible, the link and DOIs to these."
  },
  {
    "objectID": "evaluation/reporting.html#des-checklist-derived-from-ispor-sdm",
    "href": "evaluation/reporting.html#des-checklist-derived-from-ispor-sdm",
    "title": "Reporting guidelines",
    "section": "DES checklist derived from ISPOR-SDM",
    "text": "DES checklist derived from ISPOR-SDM\nOf the 18 items in the checklist:\n\n\nX were met fully (✅)\nX were partially met (🟡)\nX were not met (❌)\nX were not applicable (N/A)\n\n\n\n\n\n\n\n\n\n\n\nItem\nAssessed if…\nMet by study?\nEvidence/location\n\n\n\n\nModel conceptualisation\n\n\n\n\n\n1 Is the focused health-related decision problem clarified?\n…the decision problem under investigation was defined. DES studies included different types of decision problems, eg, those listed in previously developed taxonomies.\n\n\n\n\n2 Is the modeled healthcare setting/health condition clarified?\n…the physical context/scope (eg, a certain healthcare unit or a broader system) or disease spectrum simulated was described.\n\n\n\n\n3 Is the model structure described?\n…the model’s conceptual structure was described in the form of either graphical or text presentation.\n\n\n\n\n4 Is the time horizon given?\n…the time period covered by the simulation was reported.\n\n\n\n\n5 Are all simulated strategies/scenarios specified?\n…the comparators under test were described in terms of their components, corresponding variations, etc\n\n\n\n\n6 Is the target population described?\n…the entities simulated and their main attributes were characterized.\n\n\n\n\nParamaterisation and uncertainty assessment\n\n\n\n\n\n7 Are data sources informing parameter estimations provided?\n…the sources of all data used to inform model inputs were reported.\n\n\n\n\n8 Are the parameters used to populate model frameworks specified?\n…all relevant parameters fed into model frameworks were disclosed.\n\n\n\n\n9 Are model uncertainties discussed?\n…the uncertainty surrounding parameter estimations and adopted statistical methods (eg, 95% confidence intervals or possibility distributions) were reported.\n\n\n\n\n10 Are sensitivity analyses performed and reported?\n…the robustness of model outputs to input uncertainties was examined, for example via deterministic (based on parameters’ plausible ranges) or probabilistic (based on a priori-defined probability distributions) sensitivity analyses, or both.\n\n\n\n\nValidation\n\n\n\n\n\n11 Is face validity evaluated and reported?\n…it was reported that the model was subjected to the examination on how well model designs correspond to the reality and intuitions. It was assumed that this type of validation should be conducted by external evaluators with no stake in the study.\n\n\n\n\n12 Is cross validation performed and reported\n…comparison across similar modeling studies which deal with the same decision problem was undertaken.\n\n\n\n\n13 Is external validation performed and reported?\n…the modeler(s) examined how well the model’s results match the empirical data of an actual event modeled.\n\n\n\n\n14 Is predictive validation performed or attempted?\n…the modeler(s) examined the consistency of a model’s predictions of a future event and the actual outcomes in the future. If this was not undertaken, it was assessed whether the reasons were discussed.\n\n\n\n\nGeneralisability and stakeholder involvement\n\n\n\n\n\n15 Is the model generalizability issue discussed?\n…the modeler(s) discussed the potential of the resulting model for being applicable to other settings/populations (single/multiple application).\n\n\n\n\n16 Are decision makers or other stakeholders involved in modeling?\n…the modeler(s) reported in which part throughout the modeling process decision makers and other stakeholders (eg, subject experts) were engaged.\n\n\n\n\n17 Is the source of funding stated?\n…the sponsorship of the study was indicated.\n\n\n\n\n18 Are model limitations discussed?\n…limitations of the assessed model, especially limitations of interest to decision makers, were discussed."
  },
  {
    "objectID": "logbook/logbook.html",
    "href": "logbook/logbook.html",
    "title": "Logbook",
    "section": "",
    "text": "These diary entries record daily progress in reproduction of the study, providing a transparent and detailed record of work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay 4\n\n\n\n\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nJul 31, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 3\n\n\n\n\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nJul 30, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 2\n\n\n\n\n\n\nread\n\n\nscope\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nJul 29, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1\n\n\n\n\n\n\nsetup\n\n\n\n\n\n\n\n\n\nJul 26, 2024\n\n\nAmy Heather\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "evaluation/reproduction_report.html",
    "href": "evaluation/reproduction_report.html",
    "title": "Summary report",
    "section": "",
    "text": "Please note: This is a template page and has not yet been completed"
  },
  {
    "objectID": "evaluation/reproduction_report.html#study",
    "href": "evaluation/reproduction_report.html#study",
    "title": "Summary report",
    "section": "Study",
    "text": "Study\n\n[Authors]. [Title]. [Journal] [Volume], [Edition] ([Year]). &lt;[URL]&gt;.\n\n[Paragraph summarising model]"
  },
  {
    "objectID": "evaluation/reproduction_report.html#computational-reproducibility",
    "href": "evaluation/reproduction_report.html#computational-reproducibility",
    "title": "Summary report",
    "section": "Computational reproducibility",
    "text": "Computational reproducibility\nSuccessfully reproduced X out of X (X%) of items from the scope in Xh Xm (X%).\nRequired troubleshooting:\n\n[List of required changes to code]\n\n\nItem XItem YFigure 4\n\n\n[One sentence description of item X]\n[Display side-by-side] \n\n\n[Set-up as for Item X]\n\n\n[Set-up as for Item X]"
  },
  {
    "objectID": "evaluation/reproduction_report.html#evaluation-against-guidelines",
    "href": "evaluation/reproduction_report.html#evaluation-against-guidelines",
    "title": "Summary report",
    "section": "Evaluation against guidelines",
    "text": "Evaluation against guidelines\n\n\n                                                \n\n\nContext: The original study repository was evaluated against criteria from journal badges relating to how open and reproducible the model is and against guidance for sharing artefacts from the STARS framework. The original study article and supplementary materials (excluding code) were evaluated against reporting guidelines for DES models: STRESS-DES, and guidelines adapted from ISPOR-SDM."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducing Kim et al. 2021",
    "section": "",
    "text": "This book captures the reproduction of:\n\nKim LG, Sweeting MJ, Armer M, Jacomelli J, Nasim A, Harrison SC. Modelling the impact of changes to abdominal aortic aneurysm screening and treatment services in England during the COVID-19 pandemic. PLoS ONE 16(6): e0253327 (2021). https://doi.org/10.1371/journal.pone.0253327.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nSummary - summary of the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Reproducing Kim et al. 2021",
    "section": "",
    "text": "This book captures the reproduction of:\n\nKim LG, Sweeting MJ, Armer M, Jacomelli J, Nasim A, Harrison SC. Modelling the impact of changes to abdominal aortic aneurysm screening and treatment services in England during the COVID-19 pandemic. PLoS ONE 16(6): e0253327 (2021). https://doi.org/10.1371/journal.pone.0253327.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nSummary - summary of the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#project-team",
    "href": "index.html#project-team",
    "title": "Reproducing Kim et al. 2021",
    "section": "Project team",
    "text": "Project team\n\n\nConducting this reproduction:\n\nAmy Heather \n\nProviding support during the reproduction:\n\nThomas Monks \nAlison Harper \n\nOther members of the team on STARS:\n\nNavonil Mustafee \nAndrew Mayne"
  },
  {
    "objectID": "index.html#protocol",
    "href": "index.html#protocol",
    "title": "Reproducing Kim et al. 2021",
    "section": "Protocol",
    "text": "Protocol\nThe protocol for this work is summarised in the diagram below and archived on Zenodo:\n\nHeather, A., Monks, T., Harper, A., Mustafee, N., & Mayne, A. (2024). Protocol for assessing the computational reproducibility of discrete-event simulation models on STARS. Zenodo. https://doi.org/10.5281/zenodo.12179846.\n\n\n\n\nWorkflow for computational reproducibility assessment"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Reproducing Kim et al. 2021",
    "section": "Citation",
    "text": "Citation\nAPA:\nHeather A., Monks T., Harper A. (2024). STARS: Computational reproducibility of Kim et al. 2021 (version 0.1.0). URL: https://github.com/pythonhealthdatascience/stars-reproduce-kim-2021\nSee CITATION.cff and citation_bibtex.bib for alternative formats."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Reproducing Kim et al. 2021",
    "section": "License",
    "text": "License\nSee License page."
  },
  {
    "objectID": "quarto_site/reproduction_readme.html",
    "href": "quarto_site/reproduction_readme.html",
    "title": "README for reproduction",
    "section": "",
    "text": "Please note: This is a template README and has not yet been completed\n\n\n\nTBC\n\n\n\nTBC\n\n\n\n\n\nTBC\n\n\n\nTBC\n\n\n\nTBC\n\n\n\n\nTBC\n\n\n\n\nTBC\n\n\n\nTBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#model-summary",
    "href": "quarto_site/reproduction_readme.html#model-summary",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#scope-of-the-reproduction",
    "href": "quarto_site/reproduction_readme.html#scope-of-the-reproduction",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#reproducing-these-results",
    "href": "quarto_site/reproduction_readme.html#reproducing-these-results",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC\n\n\n\nTBC\n\n\n\nTBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#reproduction-specs-and-runtime",
    "href": "quarto_site/reproduction_readme.html#reproduction-specs-and-runtime",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#citation",
    "href": "quarto_site/reproduction_readme.html#citation",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "quarto_site/reproduction_readme.html#license",
    "href": "quarto_site/reproduction_readme.html#license",
    "title": "README for reproduction",
    "section": "",
    "text": "TBC"
  },
  {
    "objectID": "evaluation/reproduction_success.html",
    "href": "evaluation/reproduction_success.html",
    "title": "Reproduction success",
    "section": "",
    "text": "Please note: This page is in-progress and has not yet been completed\nOf the 10 items in the scope, X% (X out of 10) were considered to be successfully reproduced.\nAs cited throughout, images on this page are sourced from Kim et al. (2021)\nNote: This items have been reproduced with simulations containing 1,000,000 people (instead of 10,000,000) as that is very computationally expensive. We felt that, with 1,000,000 people, results are reasonably similar enough to be satisified with reproduction, whilst still being feasible to run on our machines."
  },
  {
    "objectID": "evaluation/reproduction_success.html#time-to-completion",
    "href": "evaluation/reproduction_success.html#time-to-completion",
    "title": "Reproduction success",
    "section": "Time-to-completion",
    "text": "Time-to-completion\nNon-interactive plot:\n\n\n\n\n\n\n\n\n\nInteractive plot:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-1",
    "href": "evaluation/reproduction_success.html#figure-1",
    "title": "Reproduction success",
    "section": "Figure 1",
    "text": "Figure 1\n\nOriginal (Kim et al. (2021)):\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#table-2",
    "href": "evaluation/reproduction_success.html#table-2",
    "title": "Reproduction success",
    "section": "Table 2",
    "text": "Table 2\nOriginal (Kim et al. (2021)):\n\n\n\n\n\nReproduction:\n\n\n\n\n\n\n\n\n\nLength of delay to invitation\nExcess AAA deaths (excess emergency operations) in Model I1*\nAttendance rate at primary scan\nExcess AAA deaths (excess emergency operations) in Model I2*\n\n\n\n\n0\n6m\n0 (3)\n65%\n61 (32)\n\n\n1\n12m\n0 (0)\n55%\n127 (67)\n\n\n2\n24m\n0 (1)\n45%\n184 (96)\n\n\n3\n36m\n21 (14)\nNaN\nNaN\n\n\n4\n48m\n56 (35)\nNaN\nNaN\n\n\n5\n60m\n108 (56)\nNaN\nNaN"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-2",
    "href": "evaluation/reproduction_success.html#figure-2",
    "title": "Reproduction success",
    "section": "Figure 2",
    "text": "Figure 2\nOriginal (Kim et al. (2021)):\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-3",
    "href": "evaluation/reproduction_success.html#figure-3",
    "title": "Reproduction success",
    "section": "Figure 3",
    "text": "Figure 3\nOriginal (Kim et al. (2021)):\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#in-text-result-1",
    "href": "evaluation/reproduction_success.html#in-text-result-1",
    "title": "Reproduction success",
    "section": "In-text result 1",
    "text": "In-text result 1\nIn bold are the items not captured in Table 3 or Figure 3:\n“Suspending ultrasound scans in the surveillance cohort could result in 9 (0.4% increase) additional AAA-related deaths if scans were suspended for one year (Table 3, Fig 3). Of these, 2 (1% increase) are in the sub-group measuring 4.5–4.9 cm at the start of the pandemic and 7 (8% increase) in the sub-group measuring 5.0–5.4 cm; &lt;0.1 are in the 3.0–4.4 cm sub-group. More pronounced effects are evident for suspension for two years and beyond. Suspending surveillance for two years could result in 40 excess AAA-related deaths overall; a 1.9% increase over the lifetime of the surveillance cohort. Of these, 1 is in the 3.0–4.4 cm sub-group and 17 (7% increase) in the 4.5–4.9cm sub-group. However, the remaining 22 excess deaths are in the 5.0–5.4cm range, corresponding to a 24% increase in AAA-related deaths in this sub-group.”\nReproduction:\nTBC"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-4",
    "href": "evaluation/reproduction_success.html#figure-4",
    "title": "Reproduction success",
    "section": "Figure 4",
    "text": "Figure 4\nOriginal (Kim et al. (2021)):\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-5",
    "href": "evaluation/reproduction_success.html#figure-5",
    "title": "Reproduction success",
    "section": "Figure 5",
    "text": "Figure 5\nOriginal (Kim et al. (2021)):\n\n\n\n\n\nReproduction:\nTBC"
  },
  {
    "objectID": "evaluation/reproduction_success.html#table-3",
    "href": "evaluation/reproduction_success.html#table-3",
    "title": "Reproduction success",
    "section": "Table 3",
    "text": "Table 3\nOriginal (Kim et al. (2021)):\n\n\n\n\n\nReproduction:\nTBC"
  },
  {
    "objectID": "evaluation/reproduction_success.html#supplementary-figure-3",
    "href": "evaluation/reproduction_success.html#supplementary-figure-3",
    "title": "Reproduction success",
    "section": "Supplementary figure 3",
    "text": "Supplementary figure 3\nOriginal (Kim et al. (2021)):\n\n\n\n\n\nReproduction:\nTBC"
  },
  {
    "objectID": "evaluation/reproduction_success.html#supplementary-table-2",
    "href": "evaluation/reproduction_success.html#supplementary-table-2",
    "title": "Reproduction success",
    "section": "Supplementary table 2",
    "text": "Supplementary table 2\nOriginal (Kim et al. (2021)):"
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html",
    "href": "logbook/posts/2024_07_31/index.html",
    "title": "Day 4",
    "section": "",
    "text": "Note\n\n\n\nTBC. Total time used: TBCh TBCm (TBC%)."
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#run-surv-scenario-2",
    "href": "logbook/posts/2024_07_31/index.html#run-surv-scenario-2",
    "title": "Day 4",
    "section": "09.12-09.16: Run surv scenario 2",
    "text": "09.12-09.16: Run surv scenario 2\nUpdate renv on remote machine, and then set surv scen2 to run.\nTimings:\n\nFirst run: 14.850 minutes = 891 seconds = 14 minutes 51 seconds\nAll runs: 99.651 minutes = 5979 seconds = 1 hour 39 minutes 39 seconds"
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#figure-2",
    "href": "logbook/posts/2024_07_31/index.html#figure-2",
    "title": "Day 4",
    "section": "09.20-09.58: Figure 2",
    "text": "09.20-09.58: Figure 2\nFixed dimensions of Figure 1 so it doesn’t change each time I re-run with different window widths. Then resumed work on Figure 2, adapting Figure 1 code to create functions that can be used to produce both plots.\nSatisfied this is reproduced at 09.58.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 539\n\n# Times from today\ntimes = [\n    ('09.12', '09.16'),\n    ('09.20', '09.58')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 42m, or 0h 42m\nTotal used to date: 581m, or 9h 41m\nTime remaining: 1819m, or 30h 19m\nUsed 24.2% of 40 hours max\n\n\n\n\n\n\n\n\nReflection\n\n\n\nNice simple output from the model makes it easier to work with, as well as it being simple and similar plots with fairly minimal manipulation."
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#figure-3-and-table-3",
    "href": "logbook/posts/2024_07_31/index.html#figure-3-and-table-3",
    "title": "Day 4",
    "section": "10.09-10.27: Figure 3 and Table 3",
    "text": "10.09-10.27: Figure 3 and Table 3\nUsing surv scen 1 (as in figure legend and article), starting working on Figure 3 and part of Table 3, adapting my prior functions.\nI realised the output for scenario 1 doesn’t include a result from delay 0, so I will need the outputs from the base scenario scen0 to create this plot. I have not yet generated these.\nThis will also need different scaling. As in the Table 3 caption:\n\nNational surveillance cohort March 2020: n=15376\nExpected AAA deaths in status quo: n=2152\nExpected emergency operations in status quo: n=745"
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#set-surv-scenario-0-to-run-on-remote-machine",
    "href": "logbook/posts/2024_07_31/index.html#set-surv-scenario-0-to-run-on-remote-machine",
    "title": "Day 4",
    "section": "10.56-11.02: Set surv scenario 0 to run on remote machine",
    "text": "10.56-11.02: Set surv scenario 0 to run on remote machine\nFirst had to push and pull changes, and then update surv scenario 0 R script (as we have done for others) (parallel, 1 million, csv, etc.)\nTimings:\n\n4.463 minutes = 268 seconds = 4 minutes 28 seconds"
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#set-surv-scenario-3-to-run-on-remote-machine",
    "href": "logbook/posts/2024_07_31/index.html#set-surv-scenario-3-to-run-on-remote-machine",
    "title": "Day 4",
    "section": "11.06-11.07: Set surv scenario 3 to run on remote machine",
    "text": "11.06-11.07: Set surv scenario 3 to run on remote machine\nTimings:\n\nFirst run: 13.303 minutes\nFull run: 81.663 minutes"
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#returning-to-figure-3-and-a-subset-of-table-3",
    "href": "logbook/posts/2024_07_31/index.html#returning-to-figure-3-and-a-subset-of-table-3",
    "title": "Day 4",
    "section": "11.11-11.24: Returning to Figure 3 and a subset of Table 3",
    "text": "11.11-11.24: Returning to Figure 3 and a subset of Table 3\nWith scenario 0 results, I could finish making the subset for Table 3, and completed Figure 3.\nSatisfied Figure 3 is reproduced at 11.24.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 539\n\n# Times from today\ntimes = [\n    ('09.12', '09.16'),\n    ('09.20', '09.58'),\n    ('10.09', '10.27'),\n    ('10.56', '11.02'),\n    ('11.06', '11.07'),\n    ('11.11', '11.24')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 80m, or 1h 20m\nTotal used to date: 619m, or 10h 19m\nTime remaining: 1781m, or 29h 41m\nUsed 25.8% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#working-on-figure-4",
    "href": "logbook/posts/2024_07_31/index.html#working-on-figure-4",
    "title": "Day 4",
    "section": "11.31-11.55, 12.43-13.00: Working on Figure 4",
    "text": "11.31-11.55, 12.43-13.00: Working on Figure 4\nSurv_scen2 includes s2.1 and s2.2, as it varies the dropout rate for 1 year, or for 2 years. These are each in part of Table 3, and together in Figure 4."
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#set-up-surv-scen-4a-to-run",
    "href": "logbook/posts/2024_07_31/index.html#set-up-surv-scen-4a-to-run",
    "title": "Day 4",
    "section": "13.01-13.04: Set up surv scen 4a to run",
    "text": "13.01-13.04: Set up surv scen 4a to run\nTimings:\n\nFirst run:\nAll runs: 35.390 min"
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#resuming-table-3-and-figure-4",
    "href": "logbook/posts/2024_07_31/index.html#resuming-table-3-and-figure-4",
    "title": "Day 4",
    "section": "13.05-13.14: Resuming Table 3 and Figure 4",
    "text": "13.05-13.14: Resuming Table 3 and Figure 4\nHad to combine with scenario 0 again to give result when dropout rate is 0.\nSatisfied this is reproduced at 13.14.\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 539\n\n# Times from today\ntimes = [\n    ('09.12', '09.16'),\n    ('09.20', '09.58'),\n    ('10.09', '10.27'),\n    ('10.56', '11.02'),\n    ('11.06', '11.07'),\n    ('11.11', '11.24'),\n    ('11.31', '11.55'),\n    ('12.43', '13.00'),\n    ('13.01', '13.04'),\n    ('13.05', '13.14')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 133m, or 2h 13m\nTotal used to date: 672m, or 11h 12m\nTime remaining: 1728m, or 28h 48m\nUsed 28.0% of 40 hours max"
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#subset-of-table-3",
    "href": "logbook/posts/2024_07_31/index.html#subset-of-table-3",
    "title": "Day 4",
    "section": "13.22-13.29: Subset of Table 3",
    "text": "13.22-13.29: Subset of Table 3\nCreated the scenario 2 sections of table 3 using my prior functions.\n\n\n\n\n\n\nReflection\n\n\n\nGiven small size of these results dataframe, could have been handy to include them along with the code."
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#in-text-result-1",
    "href": "logbook/posts/2024_07_31/index.html#in-text-result-1",
    "title": "Day 4",
    "section": "13.32-13.40: In-text result 1",
    "text": "13.32-13.40: In-text result 1\nThe output from the model for Figure 3/Table 3 (..._surv_scen1.R) just returns total AAA deaths and not which sub-groups these belonged to.\nI couldn’t spot any code in the repository that would extra this result by these sub-groups, so set about identifying how to do this."
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#set-up-surv-scen4b-to-run",
    "href": "logbook/posts/2024_07_31/index.html#set-up-surv-scen4b-to-run",
    "title": "Day 4",
    "section": "13.53-13.55: Set up surv scen4b to run",
    "text": "13.53-13.55: Set up surv scen4b to run\nPush and pull, and set to run.\n\n\n\n\n\n\nReflection\n\n\n\nThe original study authors inclusion of seeds and parallel processing is great and really handy."
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#return-to-in-text-result-1",
    "href": "logbook/posts/2024_07_31/index.html#return-to-in-text-result-1",
    "title": "Day 4",
    "section": "13.56-14.00, 14.10-14.49, 16.07-16.16: Return to in-text result 1",
    "text": "13.56-14.00, 14.10-14.49, 16.07-16.16: Return to in-text result 1\nI ran a simple version of the model on my machine (few people) so I could inspect the scen1.surv object returned.\nscen1.surv$eventHistories is a list where each item is a person from the simulation. We can get:\n\nWhether they died - if “aaaDeath” is in their events (scen1.surv$eventHistories[[i]]$screening$events)\nTheir aaorta size - scen1.surv$eventHistories[[i]]$screening$initialAortaSizeAsMeasured\n\nI wrote a function that extracts the sizes for people who have died and counts numbers in each category. I add this to ..._surv_scen1.R, initially test running with a small number of people. This worked fine, so I then set it to run on the remote machine.\nTimings:\n\nOne run: 13.346 minutes\nAll runs: 68.854 minutes\n\nI imported the results, and then realised I would also need to run this function with ..._surv_scen0.R.\nTODO: Move function to be with other model functions, so it is imported to both scripts, and then run surv_scen0 with that function added"
  },
  {
    "objectID": "logbook/posts/2024_07_31/index.html#timings",
    "href": "logbook/posts/2024_07_31/index.html#timings",
    "title": "Day 4",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 539\n\n# Times from today\ntimes = [\n    ('09.12', '09.16'),\n    ('09.20', '09.58'),\n    ('10.09', '10.27'),\n    ('10.56', '11.02'),\n    ('11.06', '11.07'),\n    ('11.11', '11.24'),\n    ('11.31', '11.55'),\n    ('12.43', '13.00'),\n    ('13.01', '13.04'),\n    ('13.05', '13.14'),\n    ('13.22', '13.29'),\n    ('13.32', '13.40'),\n    ('13.53', '13.55'),\n    ('13.56', '14.00'),\n    ('14.10', '14.49')]\n# TODO: Finish adding times\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 193m, or 3h 13m\nTotal used to date: 732m, or 12h 12m\nTime remaining: 1668m, or 27h 48m\nUsed 30.5% of 40 hours max"
  }
]